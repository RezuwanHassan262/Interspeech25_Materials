{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":10612098,"datasetId":6544256,"databundleVersionId":10950616},{"sourceType":"datasetVersion","sourceId":4143520,"datasetId":2447262,"databundleVersionId":4200057},{"sourceType":"datasetVersion","sourceId":10604502,"datasetId":6555321,"databundleVersionId":10942218}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r ../input/python-packages2 ./","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar xvfz ./python-packages2/jiwer.tgz\n!pip install ./jiwer/jiwer-2.3.0-py3-none-any.whl -f ./ --no-index\n!tar xvfz ./python-packages2/normalizer.tgz\n!pip install ./normalizer/bnunicodenormalizer-0.0.24.tar.gz -f ./ --no-index\n!tar xvfz ./python-packages2/pyctcdecode.tgz\n!pip install ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pygtrie-2.5.0.tar.gz -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n\n!tar xvfz ./python-packages2/pypikenlm.tgz\n!pip install ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz -f ./ --no-index --no-deps\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install transformers==4.20.0 \n!pip install jiwer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom glob import glob\nfrom transformers import AutoFeatureExtractor, pipeline\nimport pandas as pd\nimport librosa\nimport IPython\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nimport torch\nimport gc\nimport wave\nfrom scipy.io import wavfile\nimport scipy.signal as sps\nimport pyctcdecode\nfrom transformers import WhisperProcessor\nfrom bnunicodenormalizer import Normalizer \n\ntqdm.pandas()\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:06:50.531193Z","iopub.execute_input":"2025-01-29T18:06:50.531585Z","iopub.status.idle":"2025-01-29T18:07:12.654454Z","shell.execute_reply.started":"2025-01-29T18:06:50.531549Z","shell.execute_reply":"2025-01-29T18:07:12.653565Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"class CFG:\n    my_model_name = '/kaggle/input/whisper-medium-finetuning/whisper-medium-trained/model'\n    processor_name = '/kaggle/input/whisper-medium-finetuning/whisper-medium-trained/processor'\n    \n# Load the processor\nprocessor = WhisperProcessor.from_pretrained(CFG.processor_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:07:12.655741Z","iopub.execute_input":"2025-01-29T18:07:12.656397Z","iopub.status.idle":"2025-01-29T18:07:13.462478Z","shell.execute_reply.started":"2025-01-29T18:07:12.656365Z","shell.execute_reply":"2025-01-29T18:07:13.461807Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# from safetensors.torch import safe_open\n\n# try:\n#     with safe_open(\"/kaggle/input/whisper-medium-trained/whisper-medium-trained/model/model.safetensors\", framework=\"pt\") as f:\n#         metadata = f.metadata()\n#         print(\"Safetensors metadata:\", metadata)\n# except Exception as e:\n#     print(\"Safetensors file is corrupted:\", e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:07:13.463599Z","iopub.execute_input":"2025-01-29T18:07:13.463816Z","iopub.status.idle":"2025-01-29T18:07:13.467252Z","shell.execute_reply.started":"2025-01-29T18:07:13.463797Z","shell.execute_reply":"2025-01-29T18:07:13.466265Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"my_asrLM = pipeline(\n    \"automatic-speech-recognition\",\n    model=CFG.my_model_name,\n    tokenizer=processor.tokenizer,  # Tokenizer from the processor\n    feature_extractor=processor.feature_extractor,  # Feature extractor from the processor\n    device=0  # Use GPU (device 0)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:07:13.468235Z","iopub.execute_input":"2025-01-29T18:07:13.468428Z","iopub.status.idle":"2025-01-29T18:07:41.114958Z","shell.execute_reply.started":"2025-01-29T18:07:13.468411Z","shell.execute_reply":"2025-01-29T18:07:41.113961Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Function declarations","metadata":{}},{"cell_type":"code","source":"from jiwer import wer,cer\n\ndef infer(audio_path):\n    speech, sr = librosa.load(audio_path, sr=processor.feature_extractor.sampling_rate)\n\n    my_LM_prediction = my_asrLM(\n                speech, chunk_length_s=112, stride_length_s=None\n            )\n\n    return my_LM_prediction['text']\n\n\ndef batch_infer(audio_paths, batch_size):\n    '''\n    infers on a batch of audio\n    args:\n      audio_paths  : list of path to audio files <list of string>\n    returns:\n      bangla predicted texts <list of string>\n    '''\n    results = []\n    for path in audio_paths:\n        results.append(infer(path))\n    \n    return results\n\n\nbnorm = Normalizer()\ndef normalize(sen):\n    _words = [bnorm(word)['normalized']  for word in sen.split()]\n    return \" \".join([word for word in _words if word is not None])\n\ndef dari(sentence):\n    try:\n        if sentence[-1]!=\"ред\":\n            sentence+=\"ред\"\n    except:\n        print(sentence)\n    return sentence\n\n\ndef directory_infer(folder_path, batch_size):\n    # audios = os.listdir(folder_path)\n    audios = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n    \n    sentences = []\n    \n    for idx in tqdm(range(0,len(audios),batch_size)):\n        batch_paths = [ os.path.join(folder_path, audio) for audio in audios[idx:idx+batch_size] ]\n        sentences+=batch_infer(batch_paths, batch_size)\n    \n    df = pd.DataFrame({'file_name' : audios, 'transcriptions' : sentences})\n    df.transcriptions= df.transcriptions.apply(lambda x:normalize(x))\n    df.transcriptions= df.transcriptions.apply(lambda x:dari(x))\n    \n    return df\n\n\ndef calc_wer_cer(ground_truth,prediction):\n    \n    ground_truth = str(ground_truth)\n    prediction = str(prediction)\n\n    WER = wer(ground_truth, prediction)\n    CER = cer(ground_truth, prediction)\n\n    return WER, CER","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:07:41.115928Z","iopub.execute_input":"2025-01-29T18:07:41.116169Z","iopub.status.idle":"2025-01-29T18:07:41.147160Z","shell.execute_reply.started":"2025-01-29T18:07:41.116148Z","shell.execute_reply":"2025-01-29T18:07:41.146363Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"district_serial = {\n                       #  'Rangpur':1,\n                       # 'Kishoreganj':2,\n                       # 'Narail':3,\n                       # 'Chittagong':4,\n                       # 'Narsingdi':5,\n                       # 'Tangail':6,\n                       # 'Habiganj':7,\n                       # 'Barishal':8,\n    \n                       'Sylhet':9,\n    \n                       # 'Sandwip':10,\n                       # 'Cumilla':11,\n                       # 'Noakhali':12,\n                       # 'Lakshmipur':13,\n                       # 'Nilphamari':14,\n                       # 'Jhenaidah':15\n                      }\nBATCH_SIZE = 16\n\nfor district in district_serial:\n    input_path = os.path.join(f\"/kaggle/input/interspeech-2025/district_wise/{district}/test\")\n    print(\"====================================================================\")\n    print(\"Current District:\", district)\n    \n    submission = directory_infer(input_path, BATCH_SIZE)\n    # print(\"Exporting:\", f\"2.{district_serial[district]}: {district}-yellowking_inference.csv\")\n    # submission.to_csv(f\"2.{district_serial[district]}: {district}-yellowking_inference.csv\", index=False)\n    \n    \n    df = pd.read_excel(f\"/kaggle/input/interspeech-2025/district_wise/{district}/{district}_test.xlsx\")\n    df = df.rename(columns={'transcriptions': 'transcripts'})\n    merged_df = pd.merge(df, submission, on=\"file_name\")\n    merged_df['model'] = 'Whisper-medium'\n    merged_df = merged_df[['model','district','file_name','transcriptions', 'transcripts']]\n    merged_df = merged_df.rename(columns={'transcriptions': 'predictions'})\n\n    WERS = []\n    CERS = []\n    \n    for gd, pr in zip(merged_df['transcripts'], merged_df['predictions']):\n        WER, CER  = calc_wer_cer(gd,pr)\n        WERS.append(WER)\n        CERS.append(CER)\n    \n    merged_df['wer'] = WERS\n    merged_df['cer'] = CERS\n\n\n    print(\"Exporting:\", f\"2.{district_serial[district]}: {district}-Whisper-medium_test_inference.xlsx\")\n    merged_df.to_excel(f\"2.{district_serial[district]}: {district}-Whisper-medium_test_inference.xlsx\", index=False)\n    \n    # print(\"Exporting:\", f\"{district}_yellowking_test_inference.csv\")\n    # merged_df.to_csv(f\"{district}_yellowking_test_inference.csv\", index=False)\n    print(\"====================================================================\")\n    print() \n\n# BATCH_SIZE = 16\n# input_path = \"/kaggle/input/final-splits/final_splits/test\"\n# submission = directory_infer(input_path, BATCH_SIZE)\n# submission.to_csv(\"test_inference.csv\", index=False)\n# submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:09:46.581629Z","iopub.execute_input":"2025-01-29T18:09:46.581995Z","iopub.status.idle":"2025-01-29T20:10:24.852290Z","shell.execute_reply.started":"2025-01-29T18:09:46.581969Z","shell.execute_reply":"2025-01-29T20:10:24.851166Z"}},"outputs":[{"name":"stdout","text":"====================================================================\nCurrent District: Sylhet\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ea17b424d64b31b01d00caf8d16414"}},"metadata":{}},{"name":"stderr","text":"Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"Exporting: 2.9: Sylhet-Whisper-medium_test_inference.xlsx\n====================================================================\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# submission = pd.read_csv('/kaggle/working/test_inference.csv')\n# submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# df = pd.read_excel('/kaggle/input/final-splits/final_splits/test/test.xlsx')\n# df = df.rename(columns={'transcriptions': 'transcripts'})\n# df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# merged_df = pd.merge(df, submission, on=\"file_name\")\n# merged_df['Model_Name'] = 'Yellowking'\n# merged_df = merged_df[['district','Model_Name','file_name','transcriptions', 'transcripts']]\n# merged_df = merged_df.rename(columns={'transcriptions': 'Predictions','district': 'District'})\n\n\nmerged_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:11:11.896113Z","iopub.execute_input":"2025-01-29T20:11:11.896830Z","iopub.status.idle":"2025-01-29T20:11:11.917620Z","shell.execute_reply.started":"2025-01-29T20:11:11.896795Z","shell.execute_reply":"2025-01-29T20:11:11.916830Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"              model district             file_name  \\\n0    Whisper-medium   Sylhet  test_sylhet_0001.wav   \n1    Whisper-medium   Sylhet  test_sylhet_0002.wav   \n2    Whisper-medium   Sylhet  test_sylhet_0003.wav   \n3    Whisper-medium   Sylhet  test_sylhet_0004.wav   \n4    Whisper-medium   Sylhet  test_sylhet_0005.wav   \n..              ...      ...                   ...   \n758  Whisper-medium   Sylhet  test_sylhet_0759.wav   \n759  Whisper-medium   Sylhet  test_sylhet_0760.wav   \n760  Whisper-medium   Sylhet  test_sylhet_0761.wav   \n761  Whisper-medium   Sylhet  test_sylhet_0762.wav   \n762  Whisper-medium   Sylhet  test_sylhet_0763.wav   \n\n                    predictions  \\\n0    ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n1    ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n2    ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n3    ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n4    ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n..                          ...   \n758  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n759  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n760  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n761  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n762  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n\n                                           transcripts       wer       cer  \n0    ржЗржЯрж╛ржЗ рждрзЛ ржЖрж░ ржУржЯрж╛ржЗ ржЖрж░ржХрж┐ ржпрж╛ ржирж┐рж▓рзЛред ржУржЦржи ржмрзЗрж╢рж┐ ржХрж╛рж░ржи рждрж╛...  1.000000  0.916667  \n1    <> рж╣рзБржо ржЖрж░рзЛ, ржЖрж░рзЛ ржХрждрж╛ ржУржЗржЫрзЗ ржпрзЗржЫрж╛ржЗ ржпрзЗржХрзБржирзБ ржЬрж┐ржирж┐рж╕ ржЖржо...  1.000000  0.904564  \n2    <> ржПржЦ ржЧрждрзЛ ржПржЦржЯрж╛ ржЧрж░рзБ ржлрж╛рж▓ржЫрзЛржЗржи ржорж╛ржирзЗ ржУржЙ ржЧрж░рзБ ржЦржпрж╝ ржирж╛ ...  1.000000  0.903670  \n3    ржмрж╛ржЯ ржпржЦржи ржжрзБржзржУ ржжрзЗржпрж╝ ржирж╛ ржХрж┐ржЪрзНржЫрзБ ржирж╛ржпрж╝ ржЗржЧрзБрж░рзЗ ржлрж╛рж▓рждрзЗ ржл...  1.000000  0.895735  \n4    рждрзЗ рж╢рзЗрж╖ ржЦрж░ржЫрзЛржЗржи ржУржЦржи ржмрзБрж▓рзЗред ржЦрж╛ржорзЛржЦрж╛ ржирж╛ ржирж┐ ржЗржЧрзБрж░ рждрж▓рзЗ ...  1.000000  0.916364  \n..                                                 ...       ...       ...  \n758  ржЗржЧрзБ ржЦрж╛ржЗржд ржЦрж░рждрж╛ржо ржирж╛, ржпрзЗржоржи ржзрж░рзЛ <> ржЖрж░ ржбржЩрзНржЧрзЗрж░ ржЖрж▓рж╛ржлрзЗ...  1.000000  0.810000  \n759  <> ржлрж╛рж░рзЗ ржирж╛ ржХрзБржи рж╕ржоржпрж╝? ржорзБрж░ржмрзНржмрж┐ <> ржЖрж░ ржХрж┐рждрж╛ ржЦржЗрждрж╛ржпрж╝...  1.000000  0.907692  \n760  <> ржЕрж░ ржирж╛ржирж┐? ржУрж╣ред ржЕрждрзНрждрзЛ ржжрзБрж▓рж╛ржмрж╛ржЗ ржЖржЫрзЛржЗржиред ржбржВ ржХржЗрж░рж╛ ржП...  0.979167  0.900415  \n761  <> ржорж╛рж╕рж┐ред ржЖржорж┐ ржЕржЗрж▓рж╛ржо ржЧрж┐ржпрж╝рж╛ ржорж╛рж╕рж┐ред рждрж╛ржЗ ржЕржЗрж▓рзЛ ржмржЗржиржЬрж┐ред...  1.000000  0.898551  \n762  ржорж╛рж░ ржмржЗржи ржжрж╛ржжрзБрж░ <> рждрзЗ ржЖржорж╛рж░ ржЦрж╛рж▓рж╛ ржирж╛ржирж┐? <> рждрж╛ржЗред рждрж╛...  1.000000  0.911877  \n\n[763 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>district</th>\n      <th>file_name</th>\n      <th>predictions</th>\n      <th>transcripts</th>\n      <th>wer</th>\n      <th>cer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0001.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>ржЗржЯрж╛ржЗ рждрзЛ ржЖрж░ ржУржЯрж╛ржЗ ржЖрж░ржХрж┐ ржпрж╛ ржирж┐рж▓рзЛред ржУржЦржи ржмрзЗрж╢рж┐ ржХрж╛рж░ржи рждрж╛...</td>\n      <td>1.000000</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0002.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>&lt;&gt; рж╣рзБржо ржЖрж░рзЛ, ржЖрж░рзЛ ржХрждрж╛ ржУржЗржЫрзЗ ржпрзЗржЫрж╛ржЗ ржпрзЗржХрзБржирзБ ржЬрж┐ржирж┐рж╕ ржЖржо...</td>\n      <td>1.000000</td>\n      <td>0.904564</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0003.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>&lt;&gt; ржПржЦ ржЧрждрзЛ ржПржЦржЯрж╛ ржЧрж░рзБ ржлрж╛рж▓ржЫрзЛржЗржи ржорж╛ржирзЗ ржУржЙ ржЧрж░рзБ ржЦржпрж╝ ржирж╛ ...</td>\n      <td>1.000000</td>\n      <td>0.903670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0004.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>ржмрж╛ржЯ ржпржЦржи ржжрзБржзржУ ржжрзЗржпрж╝ ржирж╛ ржХрж┐ржЪрзНржЫрзБ ржирж╛ржпрж╝ ржЗржЧрзБрж░рзЗ ржлрж╛рж▓рждрзЗ ржл...</td>\n      <td>1.000000</td>\n      <td>0.895735</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0005.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>рждрзЗ рж╢рзЗрж╖ ржЦрж░ржЫрзЛржЗржи ржУржЦржи ржмрзБрж▓рзЗред ржЦрж╛ржорзЛржЦрж╛ ржирж╛ ржирж┐ ржЗржЧрзБрж░ рждрж▓рзЗ ...</td>\n      <td>1.000000</td>\n      <td>0.916364</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>758</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0759.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>ржЗржЧрзБ ржЦрж╛ржЗржд ржЦрж░рждрж╛ржо ржирж╛, ржпрзЗржоржи ржзрж░рзЛ &lt;&gt; ржЖрж░ ржбржЩрзНржЧрзЗрж░ ржЖрж▓рж╛ржлрзЗ...</td>\n      <td>1.000000</td>\n      <td>0.810000</td>\n    </tr>\n    <tr>\n      <th>759</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0760.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>&lt;&gt; ржлрж╛рж░рзЗ ржирж╛ ржХрзБржи рж╕ржоржпрж╝? ржорзБрж░ржмрзНржмрж┐ &lt;&gt; ржЖрж░ ржХрж┐рждрж╛ ржЦржЗрждрж╛ржпрж╝...</td>\n      <td>1.000000</td>\n      <td>0.907692</td>\n    </tr>\n    <tr>\n      <th>760</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0761.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>&lt;&gt; ржЕрж░ ржирж╛ржирж┐? ржУрж╣ред ржЕрждрзНрждрзЛ ржжрзБрж▓рж╛ржмрж╛ржЗ ржЖржЫрзЛржЗржиред ржбржВ ржХржЗрж░рж╛ ржП...</td>\n      <td>0.979167</td>\n      <td>0.900415</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0762.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>&lt;&gt; ржорж╛рж╕рж┐ред ржЖржорж┐ ржЕржЗрж▓рж╛ржо ржЧрж┐ржпрж╝рж╛ ржорж╛рж╕рж┐ред рждрж╛ржЗ ржЕржЗрж▓рзЛ ржмржЗржиржЬрж┐ред...</td>\n      <td>1.000000</td>\n      <td>0.898551</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>Whisper-medium</td>\n      <td>Sylhet</td>\n      <td>test_sylhet_0763.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>ржорж╛рж░ ржмржЗржи ржжрж╛ржжрзБрж░ &lt;&gt; рждрзЗ ржЖржорж╛рж░ ржЦрж╛рж▓рж╛ ржирж╛ржирж┐? &lt;&gt; рждрж╛ржЗред рждрж╛...</td>\n      <td>1.000000</td>\n      <td>0.911877</td>\n    </tr>\n  </tbody>\n</table>\n<p>763 rows ├Ч 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# Calculating WER & CER","metadata":{}},{"cell_type":"code","source":"# WERS = []\n# CERS = []\n\n# for gd, pr in zip(merged_df['transcripts'], merged_df['Predictions']):\n#     WER, CER  = calc_wer_cer(gd,pr)\n#     WERS.append(WER)\n#     CERS.append(CER)\n\n# merged_df['WER'] = WERS\n# merged_df['CER'] = CERS  \n\n# merged_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# merged_df.to_csv('Yellowking_test_predictions.csv',index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"district_serial = {'Rangpur':1,\n                       'Kishoreganj':2,\n                       'Narail':3,\n                       'Chittagong':4,\n                       'Narsingdi':5,\n                       'Tangail':6,\n                       'Habiganj':7,\n                       'Barishal':8,\n                       'Sylhet':9,\n                       'Sandwip':10,\n                       'Cumilla':11,\n                       'Noakhali':12,\n                       'Lakshmipur':13,\n                       'Nilphamari':14,\n                       'Jhenaidah':15\n                      }\n\navg_wer = []\navg_cer = []\nconcat_df = pd.DataFrame(columns=['model', 'district', 'file_name', 'predictions', 'transcripts', 'wer','cer'])\n\nfor district in district_serial:\n    df = pd.read_excel(f\"2.{district_serial[district]}: {district}-Whisper-medium_test_inference.xlsx\")\n    concat_df = pd.concat([concat_df, df], ignore_index=True, axis=0)\n    \n\n    avg_w = np.average(df['wer'])\n    avg_wer.append(round(avg_w,3))\n    avg_c = np.average(df['cer'])\n    avg_cer.append(round(avg_c,3))\n                   \n\nfor i,j,k in zip(district_serial,avg_wer,avg_cer ):\n    print(i)\n    print(f'Avg. WER: {j} | Avg. CER: {k}')\n    print()\n\nconcat_df.to_excel(\"Whisper-medium_inferences.xlsx\",index =False)\nconcat_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:12:08.642930Z","iopub.execute_input":"2025-01-29T20:12:08.643305Z","iopub.status.idle":"2025-01-29T20:12:09.652392Z","shell.execute_reply.started":"2025-01-29T20:12:08.643262Z","shell.execute_reply":"2025-01-29T20:12:09.651313Z"}},"outputs":[{"name":"stdout","text":"Rangpur\nAvg. WER: 1.002 | Avg. CER: 0.877\n\nKishoreganj\nAvg. WER: 1.06 | Avg. CER: 0.891\n\nNarail\nAvg. WER: 1.0 | Avg. CER: 0.888\n\nChittagong\nAvg. WER: 1.0 | Avg. CER: 0.885\n\nNarsingdi\nAvg. WER: 0.999 | Avg. CER: 0.895\n\nTangail\nAvg. WER: 0.998 | Avg. CER: 0.883\n\nHabiganj\nAvg. WER: 1.028 | Avg. CER: 0.879\n\nBarishal\nAvg. WER: 1.005 | Avg. CER: 0.901\n\nSylhet\nAvg. WER: 1.005 | Avg. CER: 0.88\n\nSandwip\nAvg. WER: 1.008 | Avg. CER: 0.886\n\nCumilla\nAvg. WER: 1.0 | Avg. CER: 0.899\n\nNoakhali\nAvg. WER: 1.143 | Avg. CER: 0.846\n\nLakshmipur\nAvg. WER: 1.0 | Avg. CER: 0.911\n\nNilphamari\nAvg. WER: 1.0 | Avg. CER: 0.851\n\nJhenaidah\nAvg. WER: 1.022 | Avg. CER: 0.871\n\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            model district              file_name                 predictions  \\\n0  Whisper-medium  Rangpur  test_rangpur_0001.wav  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n1  Whisper-medium  Rangpur  test_rangpur_0002.wav  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n2  Whisper-medium  Rangpur  test_rangpur_0003.wav  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n3  Whisper-medium  Rangpur  test_rangpur_0004.wav  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n4  Whisper-medium  Rangpur  test_rangpur_0005.wav  ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред   \n\n                                         transcripts  wer       cer  \n0  рж╕рзБржоржи рждрж╛рж░ржкрж░ рж╣ржЗрж▓рзЛ рж░рж╛ржирж╛, рждрж╛рж░ржкрж░ ржЬрж╕рж┐ржо, ржЬрж╛ржХрж╛рж░рж┐ржпрж╝рж╛ ржПрж░...  1.0  0.753425  \n1  ржЖржкрж╛, ржХрзЗржоржи ржЖржЪрзЗржи? ржЖржЪрзЛржВ рждрзЛ ржнрж╛рж▓рзЛред ржЗржпрж╝рзНржпрж╛, ржЖржкрж╛, ржЖржкржи...  1.0  0.889447  \n2  ржорзЛрж░ ржирж╛ржо ржорзЛржЫрж╛ржорзНржоржд рж░рзЗржгрзБред ржУ, ржЖржкржирж╛рж░ ржмржпрж╝рж╕ ржХрждрзЛ ржЪржЗрж▓ржмрж╛...  1.0  0.889401  \n3  ржЖрж▓рзБред ржУ, ржмрзНржпрж╛ржЯрж╛ржХ ржпрзЗ ржмрж┐ржпрж╝рзНржпрж╛-рж╢рж╛ржжрж┐ ржХрж░рж╛ржЗржирзЗржи, рж╕ржВрж╕рж╛рж░...  1.0  0.893401  \n4  ржнрж╛рж▓рзЛ ржоржирзНржж ржЦрж╛рж▓рж┐ ржЪрж╛ржпрж╝ред ржорж╛ржЫ-ржЧрзЛрж╕рзНржд ржЦрж╛ржмрж╛рж░ ржЪрж╛ржпрж╝ ржЦрж╛рж▓рж┐...  1.0  0.932353  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>district</th>\n      <th>file_name</th>\n      <th>predictions</th>\n      <th>transcripts</th>\n      <th>wer</th>\n      <th>cer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Whisper-medium</td>\n      <td>Rangpur</td>\n      <td>test_rangpur_0001.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>рж╕рзБржоржи рждрж╛рж░ржкрж░ рж╣ржЗрж▓рзЛ рж░рж╛ржирж╛, рждрж╛рж░ржкрж░ ржЬрж╕рж┐ржо, ржЬрж╛ржХрж╛рж░рж┐ржпрж╝рж╛ ржПрж░...</td>\n      <td>1.0</td>\n      <td>0.753425</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Whisper-medium</td>\n      <td>Rangpur</td>\n      <td>test_rangpur_0002.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>ржЖржкрж╛, ржХрзЗржоржи ржЖржЪрзЗржи? ржЖржЪрзЛржВ рждрзЛ ржнрж╛рж▓рзЛред ржЗржпрж╝рзНржпрж╛, ржЖржкрж╛, ржЖржкржи...</td>\n      <td>1.0</td>\n      <td>0.889447</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Whisper-medium</td>\n      <td>Rangpur</td>\n      <td>test_rangpur_0003.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>ржорзЛрж░ ржирж╛ржо ржорзЛржЫрж╛ржорзНржоржд рж░рзЗржгрзБред ржУ, ржЖржкржирж╛рж░ ржмржпрж╝рж╕ ржХрждрзЛ ржЪржЗрж▓ржмрж╛...</td>\n      <td>1.0</td>\n      <td>0.889401</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Whisper-medium</td>\n      <td>Rangpur</td>\n      <td>test_rangpur_0004.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>ржЖрж▓рзБред ржУ, ржмрзНржпрж╛ржЯрж╛ржХ ржпрзЗ ржмрж┐ржпрж╝рзНржпрж╛-рж╢рж╛ржжрж┐ ржХрж░рж╛ржЗржирзЗржи, рж╕ржВрж╕рж╛рж░...</td>\n      <td>1.0</td>\n      <td>0.893401</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Whisper-medium</td>\n      <td>Rangpur</td>\n      <td>test_rangpur_0005.wav</td>\n      <td>ржХрж░ рж░ рж░рж░ ржд рж░ ржЗ рж░ рж░ рж░ рж░ ржХ рж░ред</td>\n      <td>ржнрж╛рж▓рзЛ ржоржирзНржж ржЦрж╛рж▓рж┐ ржЪрж╛ржпрж╝ред ржорж╛ржЫ-ржЧрзЛрж╕рзНржд ржЦрж╛ржмрж╛рж░ ржЪрж╛ржпрж╝ ржЦрж╛рж▓рж┐...</td>\n      <td>1.0</td>\n      <td>0.932353</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"model = \"Whisper-medium\"\n\nmodel_avg_wer = np.average(avg_wer)\nmodel_avg_cer = np.average(avg_cer)\n\nprint(f\"{model}\")\nprint()\nprint(f\"Average WER: {model_avg_wer} | Average CER: {model_avg_cer}\")\nprint()\nprint(\"==========================================================================================================\")\n\n\nmodel_avg_wer_concat = np.average(concat_df['wer'])\nmodel_avg_cer_concat = np.average(concat_df['cer'])\nprint()\nprint(f\"All Together\")\nprint()\nprint(f\"Average WER: {round(model_avg_wer_concat,3)} | Average CER: {round(model_avg_cer_concat,3)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:12:25.418031Z","iopub.execute_input":"2025-01-29T20:12:25.418339Z","iopub.status.idle":"2025-01-29T20:12:25.425714Z","shell.execute_reply.started":"2025-01-29T20:12:25.418316Z","shell.execute_reply":"2025-01-29T20:12:25.424513Z"}},"outputs":[{"name":"stdout","text":"Whisper-medium\n\nAverage WER: 1.0179999999999998 | Average CER: 0.8828666666666667\n\n==========================================================================================================\n\nAll Together\n\nAverage WER: 1.012 | Average CER: 0.884\n","output_type":"stream"}],"execution_count":10}]}