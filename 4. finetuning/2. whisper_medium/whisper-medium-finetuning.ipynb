{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8656136,"sourceType":"datasetVersion","datasetId":5184918}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport pandas as pd\n\nimport librosa\nimport librosa.display\n\nimport numpy as np\nimport copy\n\nimport IPython.display as ipd\n\nimport matplotlib.pyplot as plt\n\nimport random\n\nfrom collections import Counter\nfrom torch.utils.data import DataLoader\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torchaudio\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\nfrom datasets import DatasetDict\nfrom datasets import concatenate_datasets\nfrom datasets import Dataset as DS\n\nfrom transformers import (\n    WhisperFeatureExtractor,\n    WhisperTokenizer,\n    WhisperProcessor,\n    WhisperForConditionalGeneration,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    TrainerCallback,\n    TrainingArguments,\n    TrainerState,\n    TrainerControl,\n    EarlyStoppingCallback,\n    pipeline\n)\nfrom torch.optim import AdamW\n\nfrom torchmetrics.text import WordErrorRate, CharErrorRate\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\n# !pip freeze > requirements.txt","metadata":{"_uuid":"54dc4040-ea02-4940-9fe4-40afd35352ab","_cell_guid":"a5cde857-9adc-4aa6-99b5-aa1be429f562","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-23T15:18:29.800089Z","iopub.execute_input":"2025-01-23T15:18:29.800386Z","iopub.status.idle":"2025-01-23T15:18:38.718293Z","shell.execute_reply.started":"2025-01-23T15:18:29.800363Z","shell.execute_reply":"2025-01-23T15:18:38.717354Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Dataset","metadata":{"_uuid":"f4780c4c-d7f0-4224-9cdc-495136ec6bb2","_cell_guid":"93e4e26f-8444-4b76-ae3f-76a8c70259f7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"BASE_DIR = '/kaggle/input/final-splits'\ntrain_data_dir = f\"{BASE_DIR}/final_splits/train/\"\nval_data_dir = f\"{BASE_DIR}/final_splits/valid/\"\ndata_path = \"/kaggle/input/final-splits/final_splits/train/train.xlsx\"\n\ndata = pd.read_excel(data_path)\ndata[\"transcriptions\"] = data[\"transcriptions\"].str.strip()\ndata[\"file_name\"] = data[\"file_name\"].str.strip()\ndata = data.drop(columns=[\"External_ID\", \"district\",\"Split\",\"annotator\"])\ndata","metadata":{"_uuid":"f531d767-9b74-4bba-95d0-09cef98ffa9f","_cell_guid":"931fb9de-a2c5-4b20-96fa-1e80a4619fcf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-23T15:18:45.439087Z","iopub.execute_input":"2025-01-23T15:18:45.439344Z","iopub.status.idle":"2025-01-23T15:18:47.439911Z","shell.execute_reply.started":"2025-01-23T15:18:45.439324Z","shell.execute_reply":"2025-01-23T15:18:47.439072Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                      file_name  \\\n0        train_barishal (1).wav   \n1       train_barishal (10).wav   \n2      train_barishal (100).wav   \n3      train_barishal (103).wav   \n4      train_barishal (104).wav   \n...                         ...   \n13337   train_tangail (995).wav   \n13338   train_tangail (996).wav   \n13339   train_tangail (997).wav   \n13340   train_tangail (998).wav   \n13341   train_tangail (999).wav   \n\n                                          transcriptions  \n0      আসসালামু আলাইকুম, আমার নাম হাসিবুর রহমান শুব, ...  \n1      <> ভালোই লাগছে। অ্যাসাইনমেন্ট করতে বসছি একটা। ...  \n2      আমি তো বলছি ভাই ও আমারে কইবে, মানে তুই কও ক্যা...  \n3      মোর পছন্দের শখ হইলো গান হোনা। গান হোনতে ব্যাক ...  \n4      মুই সকল ধরনের গান হুনি, খালি বলিউডের হিন্দি গা...  \n...                                                  ...  \n13337  টাঙ্গাইল শহর থেইকা প্রাহ ছয় কিলোমিটার দক্ষিণে ...  \n13338  মসজিদটি মূলত বর্গাকৃতির একটি গম্বুজ বিশিষ্ট। এ...  \n13339  লাল ইট দ্বারা নির্মিত এই মসজিদটি আকারে বেশ ছোট...  \n13340  সুলতানী ও মুঘোল এই দুই আমলের স্থাপত্য রিতীর সু...  \n13341  এরপর আছে মধুপুরের রাবার বাগান। টাঙ্গাইলের মধুপ...  \n\n[13342 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>transcriptions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_barishal (1).wav</td>\n      <td>আসসালামু আলাইকুম, আমার নাম হাসিবুর রহমান শুব, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_barishal (10).wav</td>\n      <td>&lt;&gt; ভালোই লাগছে। অ্যাসাইনমেন্ট করতে বসছি একটা। ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_barishal (100).wav</td>\n      <td>আমি তো বলছি ভাই ও আমারে কইবে, মানে তুই কও ক্যা...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_barishal (103).wav</td>\n      <td>মোর পছন্দের শখ হইলো গান হোনা। গান হোনতে ব্যাক ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_barishal (104).wav</td>\n      <td>মুই সকল ধরনের গান হুনি, খালি বলিউডের হিন্দি গা...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13337</th>\n      <td>train_tangail (995).wav</td>\n      <td>টাঙ্গাইল শহর থেইকা প্রাহ ছয় কিলোমিটার দক্ষিণে ...</td>\n    </tr>\n    <tr>\n      <th>13338</th>\n      <td>train_tangail (996).wav</td>\n      <td>মসজিদটি মূলত বর্গাকৃতির একটি গম্বুজ বিশিষ্ট। এ...</td>\n    </tr>\n    <tr>\n      <th>13339</th>\n      <td>train_tangail (997).wav</td>\n      <td>লাল ইট দ্বারা নির্মিত এই মসজিদটি আকারে বেশ ছোট...</td>\n    </tr>\n    <tr>\n      <th>13340</th>\n      <td>train_tangail (998).wav</td>\n      <td>সুলতানী ও মুঘোল এই দুই আমলের স্থাপত্য রিতীর সু...</td>\n    </tr>\n    <tr>\n      <th>13341</th>\n      <td>train_tangail (999).wav</td>\n      <td>এরপর আছে মধুপুরের রাবার বাগান। টাঙ্গাইলের মধুপ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>13342 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"val_data_path = \"/kaggle/input/final-splits/final_splits/valid/valid.xlsx\"\n\nval_data = pd.read_excel(val_data_path)\nval_data[\"transcriptions\"] = val_data[\"transcriptions\"].str.strip()\nval_data[\"file_name\"] = val_data[\"file_name\"].str.strip()\nval_data = val_data.drop(columns=[\"External_ID\", \"district\",\"Split\",\"annotator\"])\nval_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T15:18:47.440718Z","iopub.execute_input":"2025-01-23T15:18:47.441306Z","iopub.status.idle":"2025-01-23T15:18:47.690481Z","shell.execute_reply.started":"2025-01-23T15:18:47.441277Z","shell.execute_reply":"2025-01-23T15:18:47.689619Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                     file_name  \\\n0       valid_barishal (1).wav   \n1      valid_barishal (10).wav   \n2     valid_barishal (100).wav   \n3     valid_barishal (101).wav   \n4     valid_barishal (102).wav   \n...                        ...   \n1661    valid_tangail (95).wav   \n1662    valid_tangail (96).wav   \n1663    valid_tangail (97).wav   \n1664    valid_tangail (98).wav   \n1665    valid_tangail (99).wav   \n\n                                         transcriptions  \n0     সঞ্জয়দা, কাম কইরা আইবে না এইরম এইরম তার, স্বাম...  \n1     কিছু কিছু ছাত্র আছে মাস্টার গোলাইয়া ওই, খাইলেও...  \n2     জমার পরে পানিডা হালাইয়া দিয়া আবার পানি দিমু, প...  \n3     এইরপর এই বান্ড বরমু। বান্ডে রাখমু। বাডা-বোডা ভ...  \n4     কি খেলা যাইয়া পছন্দ ছিলো? ছোডো বেলায় তো এই ই খ...  \n...                                                 ...  \n1661  আসসালামু আলাইকুম। আমি মোহাম্মদ সামিউল ইসলাম সৈ...  \n1662  আঞ্চলিক ভাষায় কিছুক্ষণ কথা বলবো প্রেসেন্ট ইস্য...  \n1663  আলহামদুলিল্লা! ভালো। তারপর? দিনকাল কেমন যাইতাছ...  \n1664  আগে তোর ঈদের প্ল্যান বল। ঈদের প্ল্যান, আসলাম, ...  \n1665  ঈদের পরেরদিন ইনশাআল্লা! গুরতে যাব। তুই? আমিতো ...  \n\n[1666 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>transcriptions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>valid_barishal (1).wav</td>\n      <td>সঞ্জয়দা, কাম কইরা আইবে না এইরম এইরম তার, স্বাম...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>valid_barishal (10).wav</td>\n      <td>কিছু কিছু ছাত্র আছে মাস্টার গোলাইয়া ওই, খাইলেও...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>valid_barishal (100).wav</td>\n      <td>জমার পরে পানিডা হালাইয়া দিয়া আবার পানি দিমু, প...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>valid_barishal (101).wav</td>\n      <td>এইরপর এই বান্ড বরমু। বান্ডে রাখমু। বাডা-বোডা ভ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>valid_barishal (102).wav</td>\n      <td>কি খেলা যাইয়া পছন্দ ছিলো? ছোডো বেলায় তো এই ই খ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1661</th>\n      <td>valid_tangail (95).wav</td>\n      <td>আসসালামু আলাইকুম। আমি মোহাম্মদ সামিউল ইসলাম সৈ...</td>\n    </tr>\n    <tr>\n      <th>1662</th>\n      <td>valid_tangail (96).wav</td>\n      <td>আঞ্চলিক ভাষায় কিছুক্ষণ কথা বলবো প্রেসেন্ট ইস্য...</td>\n    </tr>\n    <tr>\n      <th>1663</th>\n      <td>valid_tangail (97).wav</td>\n      <td>আলহামদুলিল্লা! ভালো। তারপর? দিনকাল কেমন যাইতাছ...</td>\n    </tr>\n    <tr>\n      <th>1664</th>\n      <td>valid_tangail (98).wav</td>\n      <td>আগে তোর ঈদের প্ল্যান বল। ঈদের প্ল্যান, আসলাম, ...</td>\n    </tr>\n    <tr>\n      <th>1665</th>\n      <td>valid_tangail (99).wav</td>\n      <td>ঈদের পরেরদিন ইনশাআল্লা! গুরতে যাব। তুই? আমিতো ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1666 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# remove punctuations\npunctuations = [\n    \"/::\\)\",\"/::\",\"(-_-)\",\"(*_*)\",\"(>_<)\",\":)\",\";)\",\":P\",\"xD\",\"-_-\",\"*_*\",\"(>_<)\",\"...\",\".\",\",\",\";\",\":\",\"!\",\"?\",\"'\",\"অ�\", \"অাবার\", \"।\"\n    \"\\\"\",\"-\",\"_\",\"/\",\"\\\\\",\"|\",\"{\",\"}\",\"[\",\"]\",\"(\",\")\",\"<\",\">\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"~\",\"`\",\"+\",\"=\",\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"৳\",\"০\",\n    \"১\",\"২\",\"৩\",\"৪\",\"৫\",\"৬\",\"৭\",\"৮\",\"৯\",\"\\n\",\"\\t\",\"\\r\",\"\\f\",\"\\v\",\"\\u00C0-\\u017F\",\"\\u2000-\\u206F\",\"\\u25A0-\\u25FF\",\"\\u2600-\\u26FF\",\"\\u2B00-\\u2BFF\",\"\\u3000-\\u303F\",\n    \"\\uFB00-\\uFB4F\",\"\\uFE00-\\uFE0F\",\"\\uFE30-\\uFE4F\",\"\\u1F600-\\u1F64F\",\"\\u1F300-\\u1F5FF\",\"\\u1F680-\\u1F6FF\",\"\\u1F1E0-\\u1F1FF\",\"\\u2600-\\u26FF\",\"\\u2700-\\u27BF\",\n    \"\\u1F300-\\u1F5FF\",\"\\u1F900-\\u1F9FF\",\"\\u1F600-\\u1F64F\",\"\\u1F680-\\u1F6FF\",\"\\u1F1E0-\\u1F1FF\",\"\\u1F600-\\u1F64F\",\n]\ndef remove_punctuations(text):\n    for punctuation in punctuations:\n        text = text.replace(punctuation, \"\")\n    return text\n\nimport re\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\n        \"[\"u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"\n        \"]+\",\n        flags=re.UNICODE,\n    )\n    return emoji_pattern.sub(r\"\", text)\ndef remove_extra_space(text):\n    text = re.sub(r\"[a-zA-Z]+\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text)\n    return text\n    \ndef remove_extra(text):\n    text = re.sub(r\"\\s+\", \" \", text)\n    return text\n\n# Apply the function to the 'transcript' column\ndata['transcriptions'] = data['transcriptions'].apply(remove_punctuations)\ndata['transcriptions'] = data['transcriptions'].apply(remove_emoji)\ndata['transcriptions'] = data['transcriptions'].apply(remove_extra_space)\ndata['transcriptions'] = data['transcriptions'].apply(remove_extra)\n\n\n# Apply the function to the 'transcript' column\nval_data['transcriptions'] = val_data['transcriptions'].apply(remove_punctuations)\nval_data['transcriptions'] = val_data['transcriptions'].apply(remove_emoji)\nval_data['transcriptions'] = val_data['transcriptions'].apply(remove_extra_space)\nval_data['transcriptions'] = val_data['transcriptions'].apply(remove_extra)","metadata":{"_uuid":"6991d3fc-aa5a-487c-8059-403033f6b1c7","_cell_guid":"7cc3dcdf-7a09-42a6-85c2-c6be7dfbd714","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-23T15:18:47.691500Z","iopub.execute_input":"2025-01-23T15:18:47.691855Z","iopub.status.idle":"2025-01-23T15:18:48.600796Z","shell.execute_reply.started":"2025-01-23T15:18:47.691822Z","shell.execute_reply":"2025-01-23T15:18:48.599747Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Model","metadata":{"_uuid":"96c9b6af-d0ce-4ef7-abd2-7c436cb243c0","_cell_guid":"14fae29d-e3f8-4540-b061-6630f032ef3b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#Setting up base model\nMODEL_NAME = \"openai/whisper-medium\"\nmodel = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME, device_map=\"auto\")\nmodel_id = \"whisper-medium\"\n\nTASK = \"transcribe\"\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(MODEL_NAME)\ntokenizer = WhisperTokenizer.from_pretrained(MODEL_NAME, language='bn', task=TASK)\nprocessor = WhisperProcessor.from_pretrained(MODEL_NAME, language='bn', task=TASK)\nids = tokenizer.encode(\"\")\ntokenizer.decode(ids)","metadata":{"_uuid":"edda3dd0-318e-4e06-9a42-d99f5091bc04","_cell_guid":"158133a5-fe24-47ca-9e3a-1ae7f6bbc8fa","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-23T15:18:48.601781Z","iopub.execute_input":"2025-01-23T15:18:48.602177Z","iopub.status.idle":"2025-01-23T15:18:52.483737Z","shell.execute_reply.started":"2025-01-23T15:18:48.602136Z","shell.execute_reply":"2025-01-23T15:18:52.482939Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'<|startoftranscript|><|bn|><|transcribe|><|notimestamps|><|endoftext|>'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need different padding methods\n        # first treat the audio inputs by simply returning torch tensors\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        # get the tokenized label sequences\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        # pad the labels to max length\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        # if bos token is appended in previous tokenization step,\n        # cut bos token here as it's append later anyways\n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n        \n        torch.cuda.empty_cache()\n\n        return batch\n\ndata_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)","metadata":{"_uuid":"3ee7c9c3-dc24-42bc-add7-054600ba9933","_cell_guid":"0d702413-c5ea-4e3b-b6fd-fe3c06025c54","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-23T15:18:52.484485Z","iopub.execute_input":"2025-01-23T15:18:52.484742Z","iopub.status.idle":"2025-01-23T15:18:52.491294Z","shell.execute_reply.started":"2025-01-23T15:18:52.484719Z","shell.execute_reply":"2025-01-23T15:18:52.490483Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def prepare_dataset(example, split):\n    if split == \"train\":\n        audio_path = train_data_dir + example[\"file_name\"]\n    elif split == \"val\":\n        audio_path = val_data_dir + example[\"file_name\"]\n    else:\n        raise ValueError(\"Invalid split specified. Expected 'train' or 'val'.\")\n    \n    # Load the audio using librosa\n    audio, sr = librosa.load(audio_path, sr=16_000)\n    \n    # Extract input features and labels\n    example[\"input_features\"] = feature_extractor(audio, sampling_rate=sr).input_features[0]\n    example[\"labels\"] = tokenizer(f\"{example['transcriptions']}\", max_length=448, padding=True, truncation=True).input_ids\n    \n    return example\n\n\ndef filter_inputs(input_audio):\n    \"\"\"filter inputs with zero input length\"\"\"\n    return 0 < len(input_audio)\n\n\ndef filter_labels(input_labels):\n    \"\"\"filter empty label sequences\"\"\"\n    return 0 < len(input_labels)   \n\n\ncer = CharErrorRate()\nwer = WordErrorRate()\n\n\n\ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    wer_res = wer(pred_str, label_str)\n    cer_res = cer(pred_str, label_str)\n\n    # print(\"WER:\",wer_res,\"| CER:\", cer_res) # to show up during running logs\n    # print(\"Pred:\",pred_str[0])\n    # print(\"Label:\",label_str[0])\n    \n    return {\"wer\": wer_res, \"cer\": cer_res}","metadata":{"_uuid":"97905dc3-12c2-4d44-8e09-a7a8dfd6315a","_cell_guid":"052bb9e9-17a1-4d72-88f1-6473ddba27b7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-23T15:18:52.493461Z","iopub.execute_input":"2025-01-23T15:18:52.493716Z","iopub.status.idle":"2025-01-23T15:18:52.510092Z","shell.execute_reply.started":"2025-01-23T15:18:52.493695Z","shell.execute_reply":"2025-01-23T15:18:52.509303Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_set = data\nval_set = val_data\n\nprint(f\"Train size: {len(train_set)}\")\nprint(f\"Val size: {len(val_set)}\")","metadata":{"_uuid":"8dd4a6f5-bba2-4e28-ac98-3d410bc33e84","_cell_guid":"67cfc1cb-3407-409f-8a68-45e402facf9f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-23T15:18:52.510925Z","iopub.execute_input":"2025-01-23T15:18:52.511253Z","iopub.status.idle":"2025-01-23T15:18:52.518943Z","shell.execute_reply.started":"2025-01-23T15:18:52.511218Z","shell.execute_reply":"2025-01-23T15:18:52.518221Z"}},"outputs":[{"name":"stdout","text":"Train size: 13342\nVal size: 1666\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def evaluate_model(model, ds_eval, tokenizer, data_collator, batch_size=1, device=\"cuda\"):\n\n    # Set up the data loader\n    test_loader = DataLoader(\n        ds_eval,\n        batch_size=batch_size,\n        collate_fn=data_collator,\n    )\n\n    # Place the model in evaluation mode\n    model.eval()\n\n    # Initialize accumulators\n    predictions = []\n    references = []\n\n    # Perform inference\n    for batch in test_loader:\n        # Move inputs to the specified device\n        input_features = batch[\"input_features\"].to(device)\n        \n        # Generate predictions\n        with torch.no_grad():\n            pred_ids = model.generate(input_features)\n        \n        # Decode predictions and references\n        preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n        refs = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n        \n        predictions.extend(preds)\n        references.extend(refs)\n\n    # Calculate Word Error Rate (WER)\n    test_wer = wer(references, predictions)\n    \n    # Return results\n    return test_wer, predictions, references\n","metadata":{"_uuid":"c239f36e-db2d-4bf4-9841-db21f07a2fe9","_cell_guid":"96aec2b8-cdb4-4c4f-95ca-44b6217dac49","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-23T15:18:52.519680Z","iopub.execute_input":"2025-01-23T15:18:52.519951Z","iopub.status.idle":"2025-01-23T15:18:52.526581Z","shell.execute_reply.started":"2025-01-23T15:18:52.519919Z","shell.execute_reply":"2025-01-23T15:18:52.525881Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Main Loop","metadata":{"_uuid":"e74acb60-6cb2-45d8-b5b4-5cda08eb118b","_cell_guid":"435c04f0-056e-49e0-8c66-9db4bd86a9b4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"set_seed()\n\n\ntrain_split = DS.from_pandas(train_set)\nval_split = DS.from_pandas(val_set)\n\n# Map the dataset with split-specific processing\nds_splits = DatasetDict({\n    'train': train_split,\n    'val': val_split,\n})\n\nprint(\"Dataset Preparation Starts\")\n\n# Apply the prepare_dataset function to each split, passing the split argument\nds_splits[\"train\"] = ds_splits[\"train\"].map(\n    lambda example: prepare_dataset(example, split=\"train\"), \n    remove_columns=ds_splits[\"train\"].column_names\n)\n\nds_splits[\"val\"] = ds_splits[\"val\"].map(\n    lambda example: prepare_dataset(example, split=\"val\"), \n    remove_columns=ds_splits[\"val\"].column_names\n)\n\n\n \n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=model_id,\n    per_device_train_batch_size=12,\n    per_device_eval_batch_size=12,\n    gradient_accumulation_steps=1,\n    gradient_checkpointing=True,\n    fp16=True,\n    learning_rate=1e-3,\n    weight_decay=1e-2,\n    warmup_steps=2,\n    num_train_epochs=1,\n    eval_strategy=\"epoch\", # or \"epochs\"\n    save_strategy=\"epoch\",\n    predict_with_generate=True,\n    # generation_max_length=448,\n    #     save_steps=2976,\n    #     eval_steps=32,\n    #     logging_steps=1000,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=False,\n    report_to=\"none\",\n    remove_unused_columns=False\n)\n\nmodel.generation_config.max_length = 448\n# model.generation_config.language = \"bn\"\n# model.generation_config.task = \"transcribe\"\n\n# model.generation_config.forced_decoder_ids = None\n# model.config.suppress_tokens = [] \n\n#Start training\noptimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=ds_splits[\"train\"],\n    eval_dataset=ds_splits[\"val\"],\n    data_collator=data_collator,\n    tokenizer=processor.feature_extractor,\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, None),\n#     callbacks=[EarlyStoppingCallback(2, 1.0)]\n)\n\n\ntrainer.train()\n\n\ntrainer.save_model(training_args.output_dir)\nprocessor.save_pretrained(training_args.output_dir)\n\n\n# Evaluate the model\nval_wer, predictions, references = evaluate_model(\n    model=model,\n    ds_eval=ds_splits[\"val\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    batch_size=1,\n    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n)\n\n# print(f\"Loss at iteration {i}: {trainer.state.log_history[-1]['loss']}\")\nprint(f\"Val WER after training: {val_wer}\")\n\n\nprint(\"Process complete.\")","metadata":{"_uuid":"0c624d80-20a7-4278-af4d-9527b19ef5f3","_cell_guid":"6bf80ce2-6a10-4096-a23d-2798bcfa25f0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}