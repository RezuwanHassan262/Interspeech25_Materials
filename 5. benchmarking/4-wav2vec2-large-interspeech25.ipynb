{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install audiosegment\n",
    "!pip install jiwer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import audiosegment\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import librosa\n",
    "tqdm.pandas()\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "from jiwer import wer, cer\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "asr = pipeline(\"automatic-speech-recognition\", model=\"auditi41/wav2vec2-large-xlsr-53-Bangla\")\n",
    "\n",
    "def w2v2_inferences(aud_path): # use the audio file as the audio source\n",
    "    transcription = asr(aud_path)['text']\n",
    "    text = str(transcription)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def infer_dis(dis):\n",
    "    dis_serial_dict = {\n",
    "        'Rangpur':1,\n",
    "        'Kishoreganj':2,\n",
    "        'Narail':3,\n",
    "        'Chittagong':4,\n",
    "        'Narsingdi':5,\n",
    "        'Tangail':6,\n",
    "        'Habiganj':7,\n",
    "        'Barishal':8,\n",
    "        'Sylhet':9,\n",
    "        'Sandwip':10,\n",
    "        'Cumilla':11,\n",
    "        'Noakhali':12\n",
    "        }\n",
    "\n",
    "    \n",
    "    data_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/test/'\n",
    "\n",
    "\n",
    "    files = os.listdir(data_dir)\n",
    "    #files = files[:10]\n",
    "    #print(files)\n",
    "\n",
    "    preds = []\n",
    "    auds = []\n",
    "\n",
    "    for i in tqdm(files):\n",
    "    \n",
    "        auds.append(i)\n",
    "        aud_path =  f\"{data_dir}{i}\"\n",
    "        #print(aud_path)\n",
    "        try:\n",
    "            pred=w2v2_inferences(aud_path)\n",
    "            #print(pred)\n",
    "            preds.append(pred)\n",
    "        except Exception as e:\n",
    "            preds.append(\"<>\")\n",
    "            #pass\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(columns = [\"file_name\", \"predictions\"])\n",
    "    df[\"file_name\"] = auds\n",
    "    df[\"predictions\"] = preds\n",
    "\n",
    "    for k,v in dis_serial_dict.items():\n",
    "        if k == dis:\n",
    "            serial = v\n",
    "\n",
    "    print()\n",
    "    print(\"============================================================================\")\n",
    "    print(f\"Dataset length of {dis}: {len(df)}\")\n",
    "    print(\"============================================================================\")\n",
    "    print()\n",
    "    df.to_excel(f\"/kaggle/working/predictions/5.{serial}: {dis}_wav2vec2_large_inferences.xlsx\",index = False)\n",
    "    print()\n",
    "    print(\"=============================== Dataframe Exported ======================================\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dists = ['Rangpur', 'Kishoreganj', 'Narail', 'Chittagong', 'Narsingdi', 'Tangail','Habiganj','Barishal','Sylhet','Sandwip','Cumilla','Noakhali']\n",
    "\n",
    "\n",
    "Path('/kaggle/working/predictions/').mkdir(parents=True, exist_ok=True)\n",
    "                                                         \n",
    "for dis in dists:\n",
    "    infer_dis(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_wer_cer(ground_truth,prediction):\n",
    "\n",
    "    ground_truth = str(ground_truth)\n",
    "    prediction = str(prediction)\n",
    "\n",
    "    WER = round(wer(ground_truth, prediction),3)\n",
    "    CER = round(cer(ground_truth, prediction),3)\n",
    "\n",
    "    return WER, CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_excel_data_dir = \"/kaggle/working/predictions/\"\n",
    "pred_excel_sheets = os.listdir(pred_excel_data_dir)\n",
    "#pred_excel_sheets\n",
    "\n",
    "dists = ['Rangpur', 'Kishoreganj', 'Narail', 'Chittagong', 'Narsingdi', 'Tangail','Habiganj','Barishal','Sylhet','Sandwip','Cumilla','Noakhali']\n",
    "\n",
    "\n",
    "Path('/kaggle/working/predictions_with_wer_cer/').mkdir(parents=True, exist_ok=True)\n",
    "pred_excel_data_dir = \"/kaggle/working/predictions/\"\n",
    "pred_excel_sheets = os.listdir(pred_excel_data_dir)\n",
    "\n",
    "for sheet in pred_excel_sheets:\n",
    "\n",
    "    if sheet[-4:] == \"xlsx\":\n",
    "        i = sheet.split(\" \")\n",
    "        i = i[1].split(\"_\")\n",
    "        i = i[0]\n",
    "        #print(i)\n",
    "\n",
    "        pred_data_path = f\"{pred_excel_data_dir}{sheet}\"\n",
    "        pred_df = pd.read_excel(pred_data_path)\n",
    "        \n",
    "        gd_df = pd.read_excel(f'/kaggle/input/interspeech-2025/district_wise/{i}/{i}_test.xlsx')\n",
    "        gd_df = gd_df[[\"file_name\",\"transcripts\",\"district\"]]            \n",
    "        merged_df = pd.merge(pred_df, gd_df, on='file_name', how='inner')  \n",
    "        merged_df['model'] = 'Wav2vec2_large'\n",
    "\n",
    "        WERS = []\n",
    "        CERS = []\n",
    "    \n",
    "        for gd, pr in zip(merged_df['transcripts'], merged_df['predictions']):\n",
    "            WER, CER  = calc_wer_cer(gd,pr)\n",
    "            WERS.append(WER)\n",
    "            CERS.append(CER)\n",
    "        \n",
    "        merged_df['wer'] = WERS\n",
    "        merged_df['cer'] = CERS\n",
    "        merged_df = merged_df[[\"model\",\"district\",\"file_name\",\"predictions\",\"transcripts\",\"wer\",\"cer\"]]\n",
    "        merged_df.to_excel(f\"/kaggle/working/predictions_with_wer_cer/wav2vec2_large_{sheet}\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wer_cer_pred_excel_data_dir = \"/kaggle/working/predictions_with_wer_cer\"\n",
    "wer_cer_pred_excel_sheets = os.listdir(wer_cer_pred_excel_data_dir)\n",
    "wer_cer_pred_excel_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# District wise WER, CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dists = ['Rangpur', 'Kishoreganj', 'Narail', 'Chittagong', 'Narsingdi', 'Tangail','Habiganj','Barishal','Sylhet','Sandwip','Cumilla','Noakhali']\n",
    "\n",
    "avg_wer = []\n",
    "avg_cer = []\n",
    "\n",
    "\n",
    "for i in wer_cer_pred_excel_sheets:\n",
    "    df = pd.read_excel(f\"{wer_cer_pred_excel_data_dir}/{i}\")\n",
    "    avg_w = np.average(df['wer'])\n",
    "    avg_wer.append(round(avg_w,3))\n",
    "    avg_c = np.average(df['cer'])\n",
    "    avg_cer.append(round(avg_c,3))\n",
    "\n",
    "\n",
    "for i,j,k in zip(dists,avg_wer,avg_cer ):\n",
    "    print()\n",
    "    print(f'{i}: Avg. WER: {j} | Avg. CER: {k}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model WER, CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = \"wav2vec2_large\"\n",
    "\n",
    "model_avg_wer = np.average(avg_wer)\n",
    "model_avg_cer = np.average(avg_cer)\n",
    "\n",
    "print(f\"{model}\")\n",
    "print()\n",
    "print(f\"Average WER: {model_avg_wer} | Average CER: {model_avg_cer}\")\n",
    "print()\n",
    "print(\"==========================================================================================================\")\n",
    "\n",
    "concat_df = pd.DataFrame(columns=['model', 'district', 'file_name', 'predictions', 'transcripts', 'wer','cer'])\n",
    "\n",
    "for i in wer_cer_pred_excel_sheets:\n",
    "    df = pd.read_excel(f\"{wer_cer_pred_excel_data_dir}/{i}\")\n",
    "    concat_df = pd.concat([concat_df, df], ignore_index=True, axis=0)\n",
    "\n",
    "\n",
    "concat_df.to_excel(f\"{model}_inferences.xlsx\",index =False)\n",
    "model_avg_wer_concat = np.average(concat_df['wer'])\n",
    "model_avg_cer_concat = np.average(concat_df['cer'])\n",
    "print()\n",
    "print(f\"All Together\")\n",
    "print()\n",
    "print(f\"Average WER: {round(model_avg_wer_concat,3)} | Average CER: {round(model_avg_cer_concat,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6544256,
     "sourceId": 10575383,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
