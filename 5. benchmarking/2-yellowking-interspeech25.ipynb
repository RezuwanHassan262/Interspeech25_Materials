{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r ../input/python-packages2 ./","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar xvfz ./python-packages2/jiwer.tgz\n!pip install ./jiwer/jiwer-2.3.0-py3-none-any.whl -f ./ --no-index\n!tar xvfz ./python-packages2/normalizer.tgz\n!pip install ./normalizer/bnunicodenormalizer-0.0.24.tar.gz -f ./ --no-index\n!tar xvfz ./python-packages2/pyctcdecode.tgz\n!pip install ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pygtrie-2.5.0.tar.gz -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n\n!tar xvfz ./python-packages2/pypikenlm.tgz\n!pip install ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz -f ./ --no-index --no-deps\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install transformers==4.20.0 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom glob import glob\nfrom transformers import AutoFeatureExtractor, pipeline\nimport pandas as pd\nimport librosa\nimport IPython\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nimport torch\nimport gc\nimport wave\nfrom scipy.io import wavfile\nimport scipy.signal as sps\nimport pyctcdecode\nfrom transformers import Wav2Vec2ProcessorWithLM\nfrom bnunicodenormalizer import Normalizer \n\ntqdm.pandas()\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"class CFG:\n    my_model_name = '../input/yellowking-dlsprint-model/YellowKing_model'\n    processor_name = '../input/yellowking-dlsprint-model/YellowKing_processor'\n    \nprocessor = Wav2Vec2ProcessorWithLM.from_pretrained(CFG.processor_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_asrLM = pipeline(\"automatic-speech-recognition\", model=CFG.my_model_name ,feature_extractor =processor.feature_extractor, tokenizer= processor.tokenizer,decoder=processor.decoder ,device=0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Function declarations","metadata":{}},{"cell_type":"code","source":"def infer(audio_path):\n    speech, sr = librosa.load(audio_path, sr=processor.feature_extractor.sampling_rate)\n\n    my_LM_prediction = my_asrLM(\n                speech, chunk_length_s=112, stride_length_s=None\n            )\n\n    return my_LM_prediction['text']\n\n\ndef batch_infer(audio_paths, batch_size):\n    '''\n    infers on a batch of audio\n    args:\n      audio_paths  : list of path to audio files <list of string>\n    returns:\n      bangla predicted texts <list of string>\n    '''\n    results = []\n    for path in audio_paths:\n        results.append(infer(path))\n    \n    return results\n\n\nbnorm = Normalizer()\ndef normalize(sen):\n    _words = [bnorm(word)['normalized']  for word in sen.split()]\n    return \" \".join([word for word in _words if word is not None])\n\ndef dari(sentence):\n    try:\n        if sentence[-1]!=\"ред\":\n            sentence+=\"ред\"\n    except:\n        print(sentence)\n    return sentence\n\n\ndef directory_infer(folder_path, batch_size):\n    # audios = os.listdir(folder_path)\n    audios = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n    \n    sentences = []\n    \n    for idx in tqdm(range(0,len(audios),batch_size)):\n        batch_paths = [ os.path.join(folder_path, audio) for audio in audios[idx:idx+batch_size] ]\n        sentences+=batch_infer(batch_paths, batch_size)\n    \n    df = pd.DataFrame({'file_name' : audios, 'transcriptions' : sentences})\n    df.transcriptions= df.transcriptions.apply(lambda x:normalize(x))\n    df.transcriptions= df.transcriptions.apply(lambda x:dari(x))\n    \n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# district_serial = {\n#     'rangpur':1,\n#     'kishoreganj':2,\n#     'narail':3,\n#     'chittagong':4,\n#     'narsingdi':5,\n#     'tangail':6,\n#     'habiganj':7,\n#     'barishal':8,\n#     'sandwip':10,\n#     'sylhet':9,\n# }\n# BATCH_SIZE = 16\n\n# for district in district_serial:\n#     input_path = os.path.join(\"/kaggle/input/only-dis/only_dis/only_dis\", district)\n#     print(\"====================================================================\")\n#     print(\"Staritng:\", district)\n    \n#     submission = directory_infer(input_path, BATCH_SIZE)\n#     submission.to_csv(f\"2.{district_serial[district]}: {district}-yellowking_inference.csv\", index=False)\n    \n#     print(\"Exporting:\", f\"2.{district_serial[district]}: {district}-yellowking_inference.csv\")\n#     print(\"====================================================================\")\n#     print()\n\nBATCH_SIZE = 16\ninput_path = \"/kaggle/input/final-splits/final_splits/test\"\nsubmission = directory_infer(input_path, BATCH_SIZE)\nsubmission.to_csv(\"test_inference.csv\", index=False)\nsubmission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_excel('/kaggle/input/final-splits/final_splits/test/test.xlsx')\ndf = df.rename(columns={'transcriptions': 'Ground_Truth'})\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df = pd.merge(df, submission, on=\"file_name\")\nmerged_df['Model_Name'] = 'Yellowking'\nmerged_df = merged_df[['Model_Name','district','file_name','External_ID','transcriptions', 'Ground_Truth']]\nmerged_df = merged_df.rename(columns={'transcriptions': 'Prediction','district': 'District'})\n\n\nmerged_df","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}