{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"machine_shape":"hm"},"accelerator":"TPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":9072709,"sourceType":"datasetVersion","datasetId":5472686},{"sourceId":9124347,"sourceType":"datasetVersion","datasetId":5197902},{"sourceId":10672472,"sourceType":"datasetVersion","datasetId":6544256}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install bnlp-toolkit","metadata":{"id":"3cf2d7be","outputId":"26f8ee88-5dc1-4696-c3a5-80af998426b2","execution":{"iopub.status.busy":"2024-08-22T13:27:34.719955Z","iopub.execute_input":"2024-08-22T13:27:34.720360Z","iopub.status.idle":"2024-08-22T13:28:04.237768Z","shell.execute_reply.started":"2024-08-22T13:27:34.720329Z","shell.execute_reply":"2024-08-22T13:28:04.236350Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from bnlp import NLTKTokenizer\ntokenizer = NLTKTokenizer()\n\nfrom tqdm import tqdm\nfrom glob import glob\nimport pandas as pd\nimport os\nimport librosa","metadata":{"id":"JBWJHFC8Ysgo","outputId":"78c2e444-5481-4ccc-9dd8-c5217787204f","execution":{"iopub.status.busy":"2024-08-22T13:28:04.240325Z","iopub.execute_input":"2024-08-22T13:28:04.240792Z","iopub.status.idle":"2024-08-22T13:28:25.963623Z","shell.execute_reply.started":"2024-08-22T13:28:04.240750Z","shell.execute_reply":"2024-08-22T13:28:25.962459Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"4lsysedtUA3t"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"standard_bangla = pd.read_csv('/kaggle/input/bengaliai-train-csv/train.csv')\n\nstandard_bangla[['sentence']]","metadata":{"id":"S07Pgc90chX1","outputId":"0c172a2f-1c92-4e60-b150-9119f7d265b4","execution":{"iopub.status.busy":"2024-08-22T13:35:01.315325Z","iopub.execute_input":"2024-08-22T13:35:01.316345Z","iopub.status.idle":"2024-08-22T13:35:08.925065Z","shell.execute_reply.started":"2024-08-22T13:35:01.316297Z","shell.execute_reply":"2024-08-22T13:35:08.923796Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Dgq7Zj-Sh-d0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"token_list = []\n\nfor sen in standard_bangla['sentence']:\n    tokens = tokenizer.word_tokenize(sen)\n    token_list.append(tokens)\n\n\nstandard_bangla['Tokens'] = token_list\n\n\nvocab_bangla = {}\n\nfor i in tqdm(standard_bangla.Tokens):\n    for j in i:\n        if j ==  \"?\" or j ==  \"!\" or j ==  \"<\" or j ==  \">\" or j ==  \"'\" or j ==  \"ред\" or j ==  \".\" or j ==  \",\":\n            pass\n        else:\n            try:\n                vocab_bangla[j]+=1\n            except:\n                vocab_bangla[j]=1\n\nstandard_words = list(vocab_bangla.keys())\n\nlen(standard_words)","metadata":{"id":"RbgaVElzca9n","outputId":"b0d1dce4-af3e-430a-adc6-4e4f880fafc8","execution":{"iopub.status.busy":"2024-08-22T13:35:11.600203Z","iopub.execute_input":"2024-08-22T13:35:11.600981Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"qd9b5nX1duOM"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Get Duration","metadata":{"id":"S9mqYS2_4uU_"}},{"cell_type":"code","source":"def hms_format(seconds:float, explicit_format=False) -> str:\n    \"\"\"Returns seconds in hours minutes seconds format.\n\n    Keyword argument:\n        explicit_format: convert format from hh:mm:ss to hh hours mm minutes ss seconds\n    \"\"\"\n    hours, seconds = divmod(seconds, 3600)\n    minutes, seconds = divmod(seconds, 60)\n\n    if explicit_format:\n        return \"{} hours {:03} minutes {:03} seconds\".format(int(hours), int(minutes), round(seconds))\n    else:\n        return \"{}:{:02}:{:02}\".format(int(hours), int(minutes), round(seconds))\n\n\ndef duration(base_dir,dataset,total_number_of_words_in_the_dataset):\n\n    dataset_size = len(dataset)\n    aud_list = list(dataset['file_name'])\n    \n    total_sec = 0\n    aud_files_from_path = []\n    \n    for wav in tqdm(glob(os.path.join(base_dir, \"*.*\"))):\n        aud_path = wav.split(\"/\")\n        aud_file = aud_path[-1]\n        \n        if aud_file in aud_list:\n            aud_files_from_path.append(aud_file)\n            d = librosa.get_duration(filename=wav)\n            total_sec+=d\n    \n    \n    hms = hms_format(seconds= total_sec, explicit_format=False)\n    \n    total_hours = round(total_sec/3600, 3)\n    mint = total_sec//60\n\n    avg_duration = round(total_sec/dataset_size, 3)\n    wpm = round(total_number_of_words_in_the_dataset/mint, 3)\n    wps = round(total_number_of_words_in_the_dataset/dataset_size, 3)\n\n    return (total_sec,\n            total_hours,\n            avg_duration,\n            wpm,\n            hms,\n            wps)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Unique Words Functions","metadata":{"id":"naf_q1Qfdumq"}},{"cell_type":"code","source":"def unique_words(path, dis):\n    \n    if type(path) == str:\n        dataset = pd.read_excel(path)\n    \n    else:\n        dataset = path    \n\n    dataset_size = len(dataset)\n    \n    district = dis\n\n    token_list = []\n\n    for sen in dataset['transcriptions']:\n        tokens = tokenizer.word_tokenize(str(sen))\n        token_list.append(tokens)\n\n    dataset['Tokens'] = token_list\n\n    vocab = {}\n    all_words = []\n\n    for i in tqdm(dataset.Tokens):\n        for j in i:\n            if j ==  \"?\" or j ==  \"!\" or j ==  \"<\" or j ==  \">\" or j ==  \"'\" or j ==  \"ред\" or j ==  \".\" or j ==  \",\":\n                pass\n            else:\n                try:\n                    vocab[j]+=1\n                except:\n                    vocab[j]=1\n\n            all_words.append(j)\n\n\n    tokenized_words = list(vocab.keys())\n    total_number_words = sum(vocab.values())\n    unique_words_frequency = len(vocab.keys())\n\n\n    ood_dict = {}\n\n    for i in tokenized_words:\n        if i not in standard_words:\n            if i in ood_dict:\n                ood_dict[i] += 1\n            else:\n                ood_dict[i] = 1\n            \n    \n    #print(ood_dict)\n    ood = list(ood_dict.keys())\n    #print(ood)\n    dataset_of_ood_words = pd.DataFrame(ood,columns = [f'Unique words ({district})'])\n    ood_words_unique = len(ood)\n    #print(ood_words_unique)\n    ood_words_total_freq = sum(ood_dict.values())\n    #print(ood_words_total_freq)\n    \n\n\n    return (dataset,\n            vocab,\n            all_words,\n            total_number_words,\n            unique_words_frequency,\n            dataset_of_ood_words,\n            ood_words_total_freq,\n            ood_words_unique,\n            ood)","metadata":{"id":"J6yhSXYDheuq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main datasets","metadata":{"id":"rzKn2aE4oE4A"}},{"cell_type":"code","source":"rangpur_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/rangpur.xlsx\")\nkishoreganj_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/kishoreganj.xlsx\")\nnarail_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/narail.xlsx\")\nchittagong_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/chittagong.xlsx\")\nnarsingdi_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/narsingdi.xlsx\")\ntangail_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/tangail.xlsx\")\nhabiganj_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/habiganj.xlsx\")\nbarishal_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/barishal.xlsx\")\nsylhet_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/sylhet.xlsx\")\nsandwip_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/sandwip.xlsx\")\ncomilla_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/comilla.xlsx\")\nnoakhali_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/noakhali.xlsx\")\n\n\n\ndists = [\"rangpur\", \"kishoreganj\", \"narail\", \"chittagong\", \"narsingdi\", \"tangail\", \"habiganj\", \"barishal\", \"sylhet\", \"sandwip\", \"comilla\", \"noakhali\"]\n\ndis_words = {}\n\nfor dis in dists:\n    \n    if dis == \"all\":\n        thesis_df = pd.concat([rangpur_df,kishoreganj_df,narail_df,chittagong_df,narsingdi_df], axis = 0)\n        path = thesis_df\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/all'\n        \n    else:\n\n        path = f'/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/{dis}.xlsx'\n        base_dir = f'/kaggle/input/only-dis/only_dis/only_dis/{dis}/'\n\n    dis = dis.capitalize()\n\n    output_1 = unique_words(path, dis)\n    \n    dataset = output_1[0]\n    dataset_size = len(dataset)\n    vocab_dict= output_1[1]\n    all_words_list = output_1[2]\n    total_number_of_words_in_the_dataset = output_1[3]\n    total_number_of_unique_words_in_the_dataset = output_1[4]\n    ood_words_dataset = output_1[5]\n    total_number_of_ood_words = output_1[6]\n    total_number_of_unique_ood_words = output_1[7]\n    dis_words[dis] = output_1[8]\n    \n\n    oov_perc_unq = total_number_of_unique_ood_words/total_number_of_unique_words_in_the_dataset\n    oov_perc_tot = total_number_of_ood_words/total_number_of_words_in_the_dataset\n \n    output_2 = duration(base_dir,dataset,total_number_of_words_in_the_dataset)\n\n\n    print(f\"====================================================== {dis} ======================================================\")\n    print()\n    print()\n    print()\n    print(f'Total Samples {dataset_size}')\n    print(f'Total number of words present in {dis} dataset: {total_number_of_words_in_the_dataset}')\n    print(f'Total number of unique words present in {dis} dataset: {total_number_of_unique_words_in_the_dataset}')\n    print(f'Total number of OOD words present in {dis} dataset: {total_number_of_ood_words}')\n    print(f'Total number of unique OOD words present in {dis} dataset: {total_number_of_unique_ood_words}')\n    print(f'OOD% in {dis} dataset (Unique words): {round(oov_perc_unq*100, 3)} %')\n    print(f'OOD% in {dis} dataset (Total words): {round(oov_perc_tot*100, 3)} %')\n    print()\n    print(f\"Total Duration: {output_2[4]}\")\n    print(f\"Total in seconds: {output_2[0]} seconds\")\n    print(f\"Total in Hours: {output_2[1]} hours\")\n    print(f\"Average record size: {output_2[2]} seconds\")\n    print(f\"Words per minute: {output_2[3]} \")\n    print(f'Words per sample: {output_2[5]} words')\n    print()\n    print()\n    print()\n    print(f\"###################################################################################################################\")\n    print()\n    print()\n    print()\n    \n\noutput_df = pd.DataFrame()\n\nfor dis in dists:\n    output_df = pd.concat(\n        [output_df,\n        pd.DataFrame({dis : dis_words[dis]})],\n        axis = 1\n    )\noutput_df","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:18:18.275051Z","iopub.execute_input":"2024-08-22T13:18:18.276130Z","iopub.status.idle":"2024-08-22T13:18:24.364128Z","shell.execute_reply.started":"2024-08-22T13:18:18.276064Z","shell.execute_reply":"2024-08-22T13:18:24.362725Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Subsets","metadata":{}},{"cell_type":"code","source":"rangpur_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Rangpur/Rangpur_train.xlsx\")\nrangpur_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Rangpur/Rangpur_test.xlsx\")\nrangpur_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Rangpur/Rangpur_valid.xlsx\")\n\nkishoreganj_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Kishoreganj/Kishoreganj_train.xlsx\")\nkishoreganj_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Kishoreganj/Kishoreganj_test.xlsx\")\nkishoreganj_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Kishoreganj/Kishoreganj_valid.xlsx\")\n\nnarail_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Narail/Narail_train.xlsx\")\nnarail_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Narail/Narail_test.xlsx\")\nnarail_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Narail/Narail_valid.xlsx\")\n\nchittagong_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Chittagong/Chittagong_train.xlsx\")\nchittagong_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Chittagong/Chittagong_test.xlsx\")\nchittagong_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Chittagong/Chittagong_valid.xlsx\")\n\nnarsingdi_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Narsingdi/Narsingdi_train.xlsx\")\nnarsingdi_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Narsingdi/Narsingdi_test.xlsx\")\nnarsingdi_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Narsingdi/Narsingdi_valid.xlsx\")\n\ntangail_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Tangail/Tangail_train.xlsx\")\ntangail_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Tangail/Tangail_test.xlsx\")\ntangail_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Tangail/Tangail_valid.xlsx\")\n\nhabiganj_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Habiganj/Habiganj_train.xlsx\")\nhabiganj_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Habiganj/Habiganj_test.xlsx\")\nhabiganj_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Habiganj/Habiganj_valid.xlsx\")\n\nbarishal_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Barishal/Barishal_train.xlsx\")\nbarishal_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Barishal/Barishal_test.xlsx\")\nbarishal_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Barishal/Barishal_valid.xlsx\")\n\nsylhet_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Sylhet/Sylhet_train.xlsx\")\nsylhet_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Sylhet/Sylhet_test.xlsx\")\nsylhet_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Sylhet/Sylhet_valid.xlsx\")\n\nsandwip_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Sandwip/Sandwip_train.xlsx\")\nsandwip_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Sandwip/Sandwip_test.xlsx\")\nsandwip_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Sandwip/Sandwip_valid.xlsx\")\n\ncomilla_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Comilla/Comilla_train.xlsx\")\ncomilla_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Comilla/Comilla_test.xlsx\")\ncomilla_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Comilla/Comilla_valid.xlsx\")\n\nnoakhali_train = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Noakhali/Noakhali_train.xlsx\")\nnoakhali_test = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Noakhali/Noakhali_test.xlsx\")\nnoakhali_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/district_wise/Noakhali/Noakhali_valid.xlsx\")\n\n\nall_train = pd.read_excel(\"/kaggle/input/interspeech-2025/train.xlsx\")\nall_test = pd.read_excel(\"/kaggle/input/interspeech-2025/test.xlsx\")\nall_valid = pd.read_excel(\"/kaggle/input/interspeech-2025/valid.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:52:45.692164Z","iopub.execute_input":"2024-08-11T12:52:45.692540Z","iopub.status.idle":"2024-08-11T12:52:50.793195Z","shell.execute_reply.started":"2024-08-11T12:52:45.692510Z","shell.execute_reply":"2024-08-11T12:52:50.791874Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:52:50.797145Z","iopub.execute_input":"2024-08-11T12:52:50.797513Z","iopub.status.idle":"2024-08-11T12:52:50.815508Z","shell.execute_reply.started":"2024-08-11T12:52:50.797483Z","shell.execute_reply":"2024-08-11T12:52:50.814338Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"trains = [rangpur_train, kishoreganj_train, narail_train, chittagong_train, narsingdi_train, tangail_train, habiganj_train, barishal_train, sylhet_train, sandwip_train, comilla_train, noakhali_train, all_train]\ndists = [\"rangpur\", \"kishoreganj\", \"narail\", \"chittagong\", \"narsingdi\", \"tangail\", \"habiganj\", \"barishal\", \"sylhet\", \"sandwip\", \"comilla\", \"noakhali\", \"all\"]\n\n\nfor dis in dists:\n\n    dis = dis.capitalize()\n    \n    if dis == 'rangpur':\n        df = rangpur_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'kishoreganj':\n        df = kishoreganj_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'narail':\n        df = narail_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'chittagong':\n        df = chittagong_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'narsingdi':\n        df = narsingdi_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'tangail':\n        df = tangail_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'habiganj':\n        df = habiganj_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'barishal':\n        df = barishal_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'sylhet':\n        df = sylhet_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'sandwip':\n        df = sandwip_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'comilla':\n        df = comilla_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'noakhali':\n        df = noakhali_train\n        base_dir = f'/kaggle/input/interspeech-2025/district_wise/{dis}/train/'\n    elif dis == 'all':\n        df = all_train\n        base_dir = f'/kaggle/input/interspeech-2025/train/'\n    \n\n    dis = dis.capitalize()\n\n    output_1 = unique_words(df, dis)\n    \n    dataset = output_1[0]\n    dataset_size = len(dataset)\n    vocab_dict= output_1[1]\n    all_words_list = output_1[2]\n    total_number_of_words_in_the_dataset = output_1[3]\n    total_number_of_unique_words_in_the_dataset = output_1[4]\n    ood_words_dataset = output_1[5]\n    total_number_of_ood_words = output_1[6]\n    total_number_of_unique_ood_words = output_1[7]\n\n    oov_perc_unq = total_number_of_unique_ood_words/total_number_of_unique_words_in_the_dataset\n    oov_perc_tot = total_number_of_ood_words/total_number_of_words_in_the_dataset\n \n    output_2 = duration(base_dir,dataset,total_number_of_words_in_the_dataset)\n\n\n    print(f\"====================================================== {dis} ======================================================\")\n    print()\n    print(f'Total Samples {dataset_size}')\n    print(f'Total number of words present in {dis} dataset: {total_number_of_words_in_the_dataset}')\n    print(f'Total number of unique words present in {dis} dataset: {total_number_of_unique_words_in_the_dataset}')\n    print(f'Total number of OOD words present in {dis} dataset: {total_number_of_ood_words}')\n    print(f'Total number of unique OOD words present in {dis} dataset: {total_number_of_unique_ood_words}')\n    print(f'OOD% in {dis} dataset (Unique words): {round(oov_perc_unq*100, 3)} %')\n    print(f'OOD% in {dis} dataset (Total words): {round(oov_perc_tot*100, 3)} %')\n    print()\n    print(f\"Total Duration: {output_2[4]}\")\n    print(f\"Total in seconds: {output_2[0]} seconds\")\n    print(f\"Total in Hours: {output_2[1]} hours\")\n    print(f\"Average record size: {output_2[2]} seconds\")\n    print(f\"Words per minute: {output_2[3]} \")\n    print(f'Words per sample: {output_2[5]} words')\n    print()\n    print()\n    print()\n    print(f\"###################################################################################################################\")\n    print()\n    print()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"tests = [rangpur_test, kishoreganj_test, narail_test, chittagong_test, narsingdi_test, tangail_test, habiganj_test, barishal_test, sylhet_test, sandwip_test, comilla_test, noakhali_test, all_test]\ndists = [\"rangpur\", \"kishoreganj\", \"narail\", \"chittagong\", \"narsingdi\", \"tangail\", \"habiganj\", \"barishal\", \"sylhet\", \"sandwip\", \"comilla\", \"noakhali\", \"all\"]\n\n\nfor dis in dists:\n    \n    if dis == 'rangpur':\n        df = rangpur_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'kishoreganj':\n        df = kishoreganj_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'narail':\n        df = narail_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'chittagong':\n        df = chittagong_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'narsingdi':\n        df = narsingdi_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'tangail':\n        df = tangail_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'habiganj':\n        df = habiganj_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'barishal':\n        df = barishal_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'sylhet':\n        df = sylhet_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'sandwip':\n        df = sandwip_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'comilla':\n        df = comilla_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'noakhali':\n        df = noakhali_test\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'all':\n        df = all_test\n        base_dir = f'/kaggle/input/interspeech-2025/test/'\n        \n    dis = dis.capitalize()\n\n    output_1 = unique_words(df, dis)\n    \n    dataset = output_1[0]\n    dataset_size = len(dataset)\n    vocab_dict= output_1[1]\n    all_words_list = output_1[2]\n    total_number_of_words_in_the_dataset = output_1[3]\n    total_number_of_unique_words_in_the_dataset = output_1[4]\n    ood_words_dataset = output_1[5]\n    total_number_of_ood_words = output_1[6]\n    total_number_of_unique_ood_words = output_1[7]\n\n    oov_perc_unq = total_number_of_unique_ood_words/total_number_of_unique_words_in_the_dataset\n    oov_perc_tot = total_number_of_ood_words/total_number_of_words_in_the_dataset\n \n    output_2 = duration(base_dir,dataset,total_number_of_words_in_the_dataset)\n\n\n    print(f\"====================================================== {dis} ======================================================\")\n    print()\n    print(f'Total Samples {dataset_size}')\n    print(f'Total number of words present in {dis} dataset: {total_number_of_words_in_the_dataset}')\n    print(f'Total number of unique words present in {dis} dataset: {total_number_of_unique_words_in_the_dataset}')\n    print(f'Total number of OOD words present in {dis} dataset: {total_number_of_ood_words}')\n    print(f'Total number of unique OOD words present in {dis} dataset: {total_number_of_unique_ood_words}')\n    print(f'OOD% in {dis} dataset (Unique words): {round(oov_perc_unq*100, 3)} %')\n    print(f'OOD% in {dis} dataset (Total words): {round(oov_perc_tot*100, 3)} %')\n    print()\n    print(f\"Total Duration: {output_2[4]}\")\n    print(f\"Total in seconds: {output_2[0]} seconds\")\n    print(f\"Total in Hours: {output_2[1]} hours\")\n    print(f\"Average record size: {output_2[2]} seconds\")\n    print(f\"Words per minute: {output_2[3]} \")\n    print(f'Words per sample: {output_2[5]} words')\n    print()\n    print()\n    print()\n    print(f\"###################################################################################################################\")\n    print()\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T13:17:30.296752Z","iopub.execute_input":"2024-08-11T13:17:30.297282Z","iopub.status.idle":"2024-08-11T13:21:13.087535Z","shell.execute_reply.started":"2024-08-11T13:17:30.297223Z","shell.execute_reply":"2024-08-11T13:21:13.086301Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#     elif dis == 'all':\n        df = all_test\n        base_dir = f'/kaggle/input/interspeech-2025/test/'Valid","metadata":{}},{"cell_type":"code","source":"valids = [rangpur_valid, kishoreganj_valid, narail_valid, chittagong_valid, narsingdi_valid, tangail_valid, habiganj_valid, barishal_valid, sylhet_valid, sandwip_valid, comilla_valid, noakhali_valid, all_valid]\ndists = [\"rangpur\", \"kishoreganj\", \"narail\", \"chittagong\", \"narsingdi\", \"tangail\", \"habiganj\", \"barishal\", \"sylhet\", \"sandwip\", \"comilla\", \"noakhali\", \"all\"]\n\n\nfor dis in dists:\n    \n    if dis == 'rangpur':\n        df = rangpur_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'kishoreganj':\n        df = kishoreganj_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'narail':\n        df = narail_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'chittagong':\n        df = chittagong_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'narsingdi':\n        df = narsingdi_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'tangail':\n        df = tangail_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'habiganj':\n        df = habiganj_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'barishal':\n        df = barishal_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'sylhet':\n        df = sylhet_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'sandwip':\n        df = sandwip_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'comilla':\n        df = comilla_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'noakhali':\n        df = noakhali_valid\n        base_dir = f'/kaggle/input/only-dis/{dis}/'\n    elif dis == 'all':\n        df = all_valid\n        base_dir = f'/kaggle/input/interspeech-2025/valid/'\n        \n    dis = dis.capitalize()\n\n    output_1 = unique_words(df, dis)\n    \n    dataset = output_1[0]\n    dataset_size = len(dataset)\n    vocab_dict= output_1[1]\n    all_words_list = output_1[2]\n    total_number_of_words_in_the_dataset = output_1[3]\n    total_number_of_unique_words_in_the_dataset = output_1[4]\n    ood_words_dataset = output_1[5]\n    total_number_of_ood_words = output_1[6]\n    total_number_of_unique_ood_words = output_1[7]\n\n    oov_perc_unq = total_number_of_unique_ood_words/total_number_of_unique_words_in_the_dataset\n    oov_perc_tot = total_number_of_ood_words/total_number_of_words_in_the_dataset\n \n    output_2 = duration(base_dir,dataset,total_number_of_words_in_the_dataset)\n\n\n    print(f\"====================================================== {dis} ======================================================\")\n    print()\n    print(f'Total Samples {dataset_size}')\n    print(f'Total number of words present in {dis} dataset: {total_number_of_words_in_the_dataset}')\n    print(f'Total number of unique words present in {dis} dataset: {total_number_of_unique_words_in_the_dataset}')\n    print(f'Total number of OOD words present in {dis} dataset: {total_number_of_ood_words}')\n    print(f'Total number of unique OOD words present in {dis} dataset: {total_number_of_unique_ood_words}')\n    print(f'OOD% in {dis} dataset (Unique words): {round(oov_perc_unq*100, 3)} %')\n    print(f'OOD% in {dis} dataset (Total words): {round(oov_perc_tot*100, 3)} %')\n    print()\n    print(f\"Total Duration: {output_2[4]}\")\n    print(f\"Total in seconds: {output_2[0]} seconds\")\n    print(f\"Total in Hours: {output_2[1]} hours\")\n    print(f\"Average record size: {output_2[2]} seconds\")\n    print(f\"Words per minute: {output_2[3]} \")\n    print(f'Words per sample: {output_2[5]} words')\n    print()\n    print()\n    print()\n    print(f\"###################################################################################################################\")\n    print()\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T13:21:13.089415Z","iopub.execute_input":"2024-08-11T13:21:13.089816Z","iopub.status.idle":"2024-08-11T13:24:41.061669Z","shell.execute_reply.started":"2024-08-11T13:21:13.089768Z","shell.execute_reply":"2024-08-11T13:24:41.060578Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}