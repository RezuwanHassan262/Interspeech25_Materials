{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9072709,"sourceType":"datasetVersion","datasetId":5472686},{"sourceId":9124347,"sourceType":"datasetVersion","datasetId":5197902},{"sourceId":9929403,"sourceType":"datasetVersion","datasetId":5508512},{"sourceId":10672472,"sourceType":"datasetVersion","datasetId":6544256}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":232.160962,"end_time":"2024-08-22T14:06:05.648759","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-08-22T14:02:13.487797","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"fd3eb7b1","cell_type":"code","source":"!pip install bnlp-toolkit","metadata":{"id":"3cf2d7be","outputId":"26f8ee88-5dc1-4696-c3a5-80af998426b2","papermill":{"duration":28.84238,"end_time":"2024-08-22T14:02:45.105099","exception":false,"start_time":"2024-08-22T14:02:16.262719","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T14:19:06.664579Z","iopub.execute_input":"2025-01-31T14:19:06.664957Z","iopub.status.idle":"2025-01-31T14:19:10.142626Z","shell.execute_reply.started":"2025-01-31T14:19:06.664927Z","shell.execute_reply":"2025-01-31T14:19:10.141746Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bnlp-toolkit in /usr/local/lib/python3.10/dist-packages (4.0.3)\nRequirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (0.2.0)\nRequirement already satisfied: gensim==4.3.2 in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (4.3.2)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.26.4)\nRequirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.10.1)\nRequirement already satisfied: sklearn-crfsuite==0.3.6 in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (0.3.6)\nRequirement already satisfied: tqdm==4.66.3 in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (4.66.3)\nRequirement already satisfied: ftfy==6.2.0 in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (6.2.0)\nRequirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.7.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (2.32.3)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.2.0->bnlp-toolkit) (0.2.13)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.3.2->bnlp-toolkit) (7.0.5)\nRequirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6->bnlp-toolkit) (0.9.11)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6->bnlp-toolkit) (1.17.0)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6->bnlp-toolkit) (0.9.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bnlp-toolkit) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bnlp-toolkit) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bnlp-toolkit) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bnlp-toolkit) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bnlp-toolkit) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bnlp-toolkit) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (2024.12.14)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim==4.3.2->bnlp-toolkit) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bnlp-toolkit) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bnlp-toolkit) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bnlp-toolkit) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bnlp-toolkit) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bnlp-toolkit) (2024.2.0)\n","output_type":"stream"}],"execution_count":13},{"id":"2df61414","cell_type":"code","source":"from bnlp import NLTKTokenizer\ntokenizer = NLTKTokenizer()\n\nfrom tqdm import tqdm\nfrom glob import glob\nimport pandas as pd\nimport os\nimport librosa","metadata":{"execution":{"iopub.status.busy":"2025-01-31T14:19:20.814859Z","iopub.execute_input":"2025-01-31T14:19:20.815206Z","iopub.status.idle":"2025-01-31T14:19:20.819583Z","shell.execute_reply.started":"2025-01-31T14:19:20.815135Z","shell.execute_reply":"2025-01-31T14:19:20.818671Z"},"id":"JBWJHFC8Ysgo","outputId":"78c2e444-5481-4ccc-9dd8-c5217787204f","papermill":{"duration":13.958343,"end_time":"2024-08-22T14:02:59.076383","exception":false,"start_time":"2024-08-22T14:02:45.118040","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"id":"6c612b1b","cell_type":"code","source":"","metadata":{"id":"4lsysedtUA3t","papermill":{"duration":0.012413,"end_time":"2024-08-22T14:02:59.101590","exception":false,"start_time":"2024-08-22T14:02:59.089177","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"a5431ba0","cell_type":"code","source":"standard_bangla = pd.read_csv('/kaggle/input/bengaliai-train-csv/train.csv')\n\nstandard_bangla[['sentence']]","metadata":{"execution":{"iopub.status.busy":"2025-01-31T14:19:24.456336Z","iopub.execute_input":"2025-01-31T14:19:24.456648Z","iopub.status.idle":"2025-01-31T14:19:27.969419Z","shell.execute_reply.started":"2025-01-31T14:19:24.456624Z","shell.execute_reply":"2025-01-31T14:19:27.968538Z"},"id":"S07Pgc90chX1","outputId":"0c172a2f-1c92-4e60-b150-9119f7d265b4","papermill":{"duration":4.441841,"end_time":"2024-08-22T14:03:03.555773","exception":false,"start_time":"2024-08-22T14:02:59.113932","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                                 sentence\n0                                   ও বলেছে আপনার ঠিকানা!\n1                      কোন মহান রাষ্ট্রের নাগরিক হতে চাও?\n2          আমি তোমার কষ্টটা বুঝছি, কিন্তু এটা সঠিক পথ না।\n3       নাচ শেষ হওয়ার পর সকলে শরীর ধুয়ে একসঙ্গে ভোজন...\n4                                     হুমম, ওহ হেই, দেখো।\n...                                                   ...\n963631                           আপনার সাথে কথা বলতে চাই।\n963632  সুতরাং পরের দিন আর-একটা ছবি না লইয়া চিত্রকর ছা...\n963633  সামাজিক কর্মকাণ্ডসমিতিতে গিয়ে দেখা যায়, শিল্পী...\n963634  গুগল ম্যাপসের সাহায্যে খুঁজে পাওয়া যাবে কোন জা...\n963635                      তোমরা আমাকে কী নাম ধরে ডাকবে?\n\n[963636 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ও বলেছে আপনার ঠিকানা!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>কোন মহান রাষ্ট্রের নাগরিক হতে চাও?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>আমি তোমার কষ্টটা বুঝছি, কিন্তু এটা সঠিক পথ না।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>নাচ শেষ হওয়ার পর সকলে শরীর ধুয়ে একসঙ্গে ভোজন...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>হুমম, ওহ হেই, দেখো।</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>963631</th>\n      <td>আপনার সাথে কথা বলতে চাই।</td>\n    </tr>\n    <tr>\n      <th>963632</th>\n      <td>সুতরাং পরের দিন আর-একটা ছবি না লইয়া চিত্রকর ছা...</td>\n    </tr>\n    <tr>\n      <th>963633</th>\n      <td>সামাজিক কর্মকাণ্ডসমিতিতে গিয়ে দেখা যায়, শিল্পী...</td>\n    </tr>\n    <tr>\n      <th>963634</th>\n      <td>গুগল ম্যাপসের সাহায্যে খুঁজে পাওয়া যাবে কোন জা...</td>\n    </tr>\n    <tr>\n      <th>963635</th>\n      <td>তোমরা আমাকে কী নাম ধরে ডাকবে?</td>\n    </tr>\n  </tbody>\n</table>\n<p>963636 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"id":"294e53eb","cell_type":"code","source":"","metadata":{"id":"Dgq7Zj-Sh-d0","papermill":{"duration":0.012337,"end_time":"2024-08-22T14:03:03.580807","exception":false,"start_time":"2024-08-22T14:03:03.568470","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"93ec6557","cell_type":"code","source":"token_list = []\n\nfor sen in standard_bangla['sentence']:\n    tokens = tokenizer.word_tokenize(sen)\n    token_list.append(tokens)\n\n\nstandard_bangla['Tokens'] = token_list\n\n\nvocab_bangla = {}\n\nfor i in tqdm(standard_bangla.Tokens):\n    for j in i:\n        if j ==  \"?\" or j ==  \"!\" or j ==  \"<\" or j ==  \">\" or j ==  \"'\" or j ==  \"।\" or j ==  \".\" or j ==  \",\":\n            pass\n        else:\n            try:\n                vocab_bangla[j]+=1\n            except:\n                vocab_bangla[j]=1\n\nstandard_words = list(vocab_bangla.keys())\n\nlen(standard_words)","metadata":{"execution":{"iopub.status.busy":"2025-01-31T14:19:31.449574Z","iopub.execute_input":"2025-01-31T14:19:31.449872Z","iopub.status.idle":"2025-01-31T14:21:15.469085Z","shell.execute_reply.started":"2025-01-31T14:19:31.449850Z","shell.execute_reply":"2025-01-31T14:21:15.468232Z"},"id":"RbgaVElzca9n","outputId":"b0d1dce4-af3e-430a-adc6-4e4f880fafc8","papermill":{"duration":179.413403,"end_time":"2024-08-22T14:06:03.006434","exception":false,"start_time":"2024-08-22T14:03:03.593031","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 963636/963636 [00:05<00:00, 178071.72it/s]\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"181509"},"metadata":{}}],"execution_count":16},{"id":"0043549d","cell_type":"code","source":"","metadata":{"id":"qd9b5nX1duOM","papermill":{"duration":0.017595,"end_time":"2024-08-22T14:06:03.042291","exception":false,"start_time":"2024-08-22T14:06:03.024696","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"0e8c9931","cell_type":"markdown","source":"# Get Duration","metadata":{"id":"S9mqYS2_4uU_","papermill":{"duration":0.017561,"end_time":"2024-08-22T14:06:03.077599","exception":false,"start_time":"2024-08-22T14:06:03.060038","status":"completed"},"tags":[]}},{"id":"b5b348b9","cell_type":"code","source":"def hms_format(seconds:float, explicit_format=False) -> str:\n    \"\"\"Returns seconds in hours minutes seconds format.\n\n    Keyword argument:\n        explicit_format: convert format from hh:mm:ss to hh hours mm minutes ss seconds\n    \"\"\"\n    hours, seconds = divmod(seconds, 3600)\n    minutes, seconds = divmod(seconds, 60)\n\n    if explicit_format:\n        return \"{} hours {:03} minutes {:03} seconds\".format(int(hours), int(minutes), round(seconds))\n    else:\n        return \"{}:{:02}:{:02}\".format(int(hours), int(minutes), round(seconds))\n\n\ndef duration(base_dir,dataset,total_number_of_words_in_the_dataset):\n\n    dataset_size = len(dataset)\n    aud_list = list(dataset['file_name'])\n    \n    total_sec = 0\n    aud_files_from_path = []\n    \n    for wav in tqdm(glob(os.path.join(base_dir, \"*.*\"))):\n        aud_path = wav.split(\"/\")\n        aud_file = aud_path[-1]\n        \n        if aud_file in aud_list:\n            aud_files_from_path.append(aud_file)\n            d = librosa.get_duration(filename=wav)\n            total_sec+=d\n    \n    \n    hms = hms_format(seconds= total_sec, explicit_format=False)\n    \n    total_hours = round(total_sec/3600, 3)\n    mint = total_sec//60\n\n    avg_duration = round(total_sec/dataset_size, 3)\n    wpm = round(total_number_of_words_in_the_dataset/mint, 3)\n    wps = round(total_number_of_words_in_the_dataset/dataset_size, 3)\n\n    return (total_sec,\n            total_hours,\n            avg_duration,\n            wpm,\n            hms,\n            wps)","metadata":{"execution":{"iopub.status.busy":"2025-01-31T14:21:46.644647Z","iopub.execute_input":"2025-01-31T14:21:46.644983Z","iopub.status.idle":"2025-01-31T14:21:46.651830Z","shell.execute_reply.started":"2025-01-31T14:21:46.644957Z","shell.execute_reply":"2025-01-31T14:21:46.650930Z"},"papermill":{"duration":0.031681,"end_time":"2024-08-22T14:06:03.126794","exception":false,"start_time":"2024-08-22T14:06:03.095113","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"dc9d4c93","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.017308,"end_time":"2024-08-22T14:06:03.161892","exception":false,"start_time":"2024-08-22T14:06:03.144584","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"f914a937","cell_type":"markdown","source":"# Unique Words Functions","metadata":{"id":"naf_q1Qfdumq","papermill":{"duration":0.017185,"end_time":"2024-08-22T14:06:03.196506","exception":false,"start_time":"2024-08-22T14:06:03.179321","status":"completed"},"tags":[]}},{"id":"77b88317","cell_type":"code","source":"def unique_words(path, dis):\n    \n    if type(path) == str:\n        dataset = pd.read_excel(path)\n    \n    else:\n        dataset = path    \n\n    dataset_size = len(dataset)\n    \n    district = dis\n\n    token_list = []\n\n    for sen in dataset['transcripts']:\n        tokens = tokenizer.word_tokenize(str(sen))\n        token_list.append(tokens)\n\n    dataset['Tokens'] = token_list\n\n    vocab = {}\n    all_words = []\n\n    for i in tqdm(dataset.Tokens):\n        for j in i:\n            if j ==  \"?\" or j ==  \"!\" or j ==  \"<\" or j ==  \">\" or j ==  \"'\" or j ==  \"।\" or j ==  \".\" or j ==  \",\":\n                pass\n            else:\n                try:\n                    vocab[j]+=1\n                except:\n                    vocab[j]=1\n\n            all_words.append(j)\n\n\n    tokenized_words = list(vocab.keys())\n    total_number_words = sum(vocab.values())\n    unique_words_frequency = len(vocab.keys())\n\n\n    ood_dict = {}\n\n    for i in tokenized_words:\n        if i not in standard_words:\n            if i in ood_dict:\n                ood_dict[i] += 1\n            else:\n                ood_dict[i] = 1\n            \n    \n    print(ood_dict)\n    ood = list(ood_dict.keys())\n    print(ood)\n    dataset_of_ood_words = pd.DataFrame(ood,columns = [f'Unique words ({district})'])\n    ood_words_unique = len(ood)\n    #print(ood_words_unique)\n    ood_words_total_freq = sum(ood_dict.values())\n    #print(ood_words_total_freq)\n    \n\n\n    return (dataset,\n            vocab,\n            all_words,\n            total_number_words,\n            unique_words_frequency,\n            dataset_of_ood_words,\n            ood_words_total_freq,\n            ood_words_unique,\n            ood)","metadata":{"execution":{"iopub.status.busy":"2025-01-31T14:21:50.003004Z","iopub.execute_input":"2025-01-31T14:21:50.003343Z","iopub.status.idle":"2025-01-31T14:21:50.010729Z","shell.execute_reply.started":"2025-01-31T14:21:50.003313Z","shell.execute_reply":"2025-01-31T14:21:50.010036Z"},"id":"J6yhSXYDheuq","papermill":{"duration":0.031991,"end_time":"2024-08-22T14:06:03.245887","exception":false,"start_time":"2024-08-22T14:06:03.213896","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"id":"164ebdf1-b875-4d09-b185-4022463249e4","cell_type":"code","source":"token_list = []\n\nfor sen in standard_bangla['sentence']:\n    tokens = tokenizer.word_tokenize(sen)\n    token_list.append(tokens)\n\n\nstandard_bangla['Tokens'] = token_list\n\n\nvocab_bangla = {}\n\nfor i in tqdm(standard_bangla.Tokens):\n    for j in i:\n        if j ==  \"?\" or j ==  \"!\" or j ==  \"<\" or j ==  \">\" or j ==  \"'\" or j ==  \"।\" or j ==  \".\" or j ==  \",\":\n            pass\n        else:\n            try:\n                vocab_bangla[j]+=1\n            except:\n                vocab_bangla[j]=1\n\nstandard_words = list(vocab_bangla.keys())\n\nlen(standard_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T14:29:51.527350Z","iopub.execute_input":"2025-01-31T14:29:51.527670Z","iopub.status.idle":"2025-01-31T14:31:35.250016Z","shell.execute_reply.started":"2025-01-31T14:29:51.527648Z","shell.execute_reply":"2025-01-31T14:31:35.249224Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 963636/963636 [00:05<00:00, 175195.12it/s]\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"181509"},"metadata":{}}],"execution_count":21},{"id":"736c0511-4b8a-4bb4-b419-721f52e0254e","cell_type":"code","source":"# Generate standard words from Bengali dataset\nprint(\"Generating standard words...\")\nstandard_bangla = pd.read_csv('/kaggle/input/bengaliai-train-csv/train.csv')\ntoken_list = []\nfor sen in standard_bangla['sentence']:\n    tokens = tokenizer.word_tokenize(sen)\n    token_list.append(tokens)\n    \nvocab_bangla = {}\nfor i in tqdm(standard_bangla.Tokens):\n    for j in i:\n        if j not in [\"?\", \"!\", \"<\", \">\", \"'\", \"।\", \".\", \",\"]:\n            try:\n                vocab_bangla[j]+=1\n            except:\n                vocab_bangla[j]=1\n\nstandard_words = list(vocab_bangla.keys())\nprint(f\"Total standard words: {len(standard_words)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T14:26:38.348295Z","iopub.execute_input":"2025-01-31T14:26:38.348621Z","iopub.status.idle":"2025-01-31T14:28:19.337756Z","shell.execute_reply.started":"2025-01-31T14:26:38.348598Z","shell.execute_reply":"2025-01-31T14:28:19.336680Z"}},"outputs":[{"name":"stdout","text":"Generating standard words...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-11c2023a3ed6>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvocab_bangla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstandard_bangla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\">\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"।\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Tokens'"],"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'Tokens'","output_type":"error"}],"execution_count":20},{"id":"d0894291-fc6f-4696-8d01-f678464f1a9b","cell_type":"code","source":"# Generate standard words from Bengali dataset\nprint(\"Generating standard words...\")\nstandard_bangla = pd.read_csv('/kaggle/input/bengaliai-train-csv/train.csv')\ntoken_list = []\nfor sen in standard_bangla['sentence']:\n    tokens = tokenizer.word_tokenize(sen)\n    token_list.append(tokens)\n\n# Add Tokens column to DataFrame - This was the missing step!\nstandard_bangla['Tokens'] = token_list\n    \nvocab_bangla = {}\nfor i in tqdm(standard_bangla.Tokens):\n    for j in i:\n        if j ==  \"?\" or j ==  \"!\" or j ==  \"<\" or j ==  \">\" or j ==  \"'\" or j ==  \"।\" or j ==  \".\" or j ==  \",\":\n            pass\n        else:\n            try:\n                vocab_bangla[j]+=1\n            except:\n                vocab_bangla[j]=1\n\nstandard_words = list(vocab_bangla.keys())\nprint(f\"Total standard words: {len(standard_words)}\")\n\ndef get_ood_words(dataset_path, dataset_type, district):\n    \"\"\"Extract OOD words from a dataset\"\"\"\n    try:\n        dataset = pd.read_excel(dataset_path)\n        token_list = []\n        \n        for sen in dataset['transcripts']:\n            tokens = tokenizer.word_tokenize(str(sen))\n            token_list.append(tokens)\n            \n        vocab = {}\n        for tokens in token_list:\n            for token in tokens:\n                if token not in [\"?\", \"!\", \"<\", \">\", \"'\", \"।\", \".\", \",\"]:\n                    vocab[token] = vocab.get(token, 0) + 1\n        \n        ood_words = [word for word in vocab if word not in standard_words]\n        return ood_words\n        \n    except Exception as e:\n        print(f\"Error processing {district} {dataset_type}: {str(e)}\")\n        return []\n\ndef create_ood_excel(ood_words_dict, output_path):\n    \"\"\"Create and save Excel file from OOD words dictionary\"\"\"\n    max_words = max(len(words) for words in ood_words_dict.values())\n    df_dict = {}\n    \n    for district in district_list:\n        words = ood_words_dict[district]\n        words_padded = words + [''] * (max_words - len(words))\n        df_dict[district.lower()] = words_padded\n    \n    df = pd.DataFrame(df_dict)\n    df.to_excel(output_path, index=False)\n    print(f\"Saved: {output_path}\")\n    return df\n\n# District list\ndistrict_list = [\"Rangpur\", \"Kishoreganj\", \"Narail\", \"Chittagong\", \"Narsingdi\", \n                \"Tangail\", \"Habiganj\", \"Barishal\", \"Sylhet\", \"Sandwip\", \"Comilla\", \"Noakhali\"]\n\n# Base directory path\nbase_dir = \"/kaggle/input/interspeech-2025/district_wise\"\n\n# Dictionary to store OOD words for each district and dataset type\ndistrict_ood_words = {\n    'test': {},\n    'train': {},\n    'valid': {},\n    'combined': {}\n}\n\n# Process each district\nfor district in tqdm(district_list, desc=\"Processing districts\"):\n    # Process test data\n    test_path = os.path.join(base_dir, district, f\"{district}_test.xlsx\")\n    district_ood_words['test'][district] = get_ood_words(test_path, 'test', district)\n    \n    # Process train data\n    train_path = os.path.join(base_dir, district, f\"{district}_train.xlsx\")\n    district_ood_words['train'][district] = get_ood_words(train_path, 'train', district)\n    \n    # Process validation data\n    valid_path = os.path.join(base_dir, district, f\"{district}_valid.xlsx\")\n    district_ood_words['valid'][district] = get_ood_words(valid_path, 'valid', district)\n    \n    # Combine all OOD words for this district\n    combined_words = set(district_ood_words['test'][district] + \n                        district_ood_words['train'][district] + \n                        district_ood_words['valid'][district])\n    district_ood_words['combined'][district] = list(combined_words)\n\n# Create Excel files\noutput_files = {\n    'test': \"/kaggle/working/district_ood_dictionary_test.xlsx\",\n    'train': \"/kaggle/working/district_ood_dictionary_train.xlsx\",\n    'valid': \"/kaggle/working/district_ood_dictionary_valid.xlsx\",\n    'combined': \"/kaggle/working/district_ood_dictionary_combined.xlsx\"\n}\n\n# Generate all Excel files\nprint(\"\\nGenerating Excel files...\")\nfor data_type, output_path in output_files.items():\n    print(f\"\\nProcessing {data_type} dataset...\")\n    df = create_ood_excel(district_ood_words[data_type], output_path)\n    print(f\"First few rows of {data_type} dataset:\")\n    display(df.head())\n    print(\"-\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T14:34:58.339859Z","iopub.execute_input":"2025-01-31T14:34:58.340203Z","iopub.status.idle":"2025-01-31T14:47:35.974917Z","shell.execute_reply.started":"2025-01-31T14:34:58.340164Z","shell.execute_reply":"2025-01-31T14:47:35.974017Z"}},"outputs":[{"name":"stdout","text":"Generating standard words...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 963636/963636 [00:05<00:00, 169014.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Total standard words: 181509\n","output_type":"stream"},{"name":"stderr","text":"Processing districts: 100%|██████████| 12/12 [10:39<00:00, 53.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nGenerating Excel files...\n\nProcessing test dataset...\nSaved: /kaggle/working/district_ood_dictionary_test.xlsx\nFirst few rows of test dataset:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      rangpur kishoreganj    narail chittagong     narsingdi     tangail  \\\n0       নেমেন       তুলছস     এট্টা     বাড়িত    হান্ড্রেডও       গানডা   \n1        হইচে        সইডা     চাহোর     হেইরহম           যহন     লাগতাছে   \n2       সাগাই  আইছে।উঠতাম      ওইরে      হইতদি  প্লেয়ারগুলা   মার্কিউরি   \n3  নিবান্নাইস     আইট্টাই      ওঠলো        ইতে        দেইখাই  মার্কিউডির   \n4       নাগান        উডুক  সেহেন্তে  মাতিয়ারে        খেইলাই        থিকা   \n\n  habiganj   barishal    sylhet sandwip      comilla noakhali  \n0     খদিন     পোলারে      ওইছে    আইবো  স্বর্ণকাররা    তারফর  \n1      ফরে     খাইয়া     যেছাই     এডে    স্বর্নকার   ইয়ানো  \n2  ফইল্লেও      লইয়া    যেকুনু   যাইবো       হইছেগা   হইত্তর  \n3    লইয়া  হিরি-মিরি    কিচ্চু      গৈ    ফাচানব্বই    হাড়ে  \n4   আইবোনে       ডাইন  বানাইয়া    কইছে        ওইয়া  কিয়ারে  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rangpur</th>\n      <th>kishoreganj</th>\n      <th>narail</th>\n      <th>chittagong</th>\n      <th>narsingdi</th>\n      <th>tangail</th>\n      <th>habiganj</th>\n      <th>barishal</th>\n      <th>sylhet</th>\n      <th>sandwip</th>\n      <th>comilla</th>\n      <th>noakhali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>নেমেন</td>\n      <td>তুলছস</td>\n      <td>এট্টা</td>\n      <td>বাড়িত</td>\n      <td>হান্ড্রেডও</td>\n      <td>গানডা</td>\n      <td>খদিন</td>\n      <td>পোলারে</td>\n      <td>ওইছে</td>\n      <td>আইবো</td>\n      <td>স্বর্ণকাররা</td>\n      <td>তারফর</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>হইচে</td>\n      <td>সইডা</td>\n      <td>চাহোর</td>\n      <td>হেইরহম</td>\n      <td>যহন</td>\n      <td>লাগতাছে</td>\n      <td>ফরে</td>\n      <td>খাইয়া</td>\n      <td>যেছাই</td>\n      <td>এডে</td>\n      <td>স্বর্নকার</td>\n      <td>ইয়ানো</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>সাগাই</td>\n      <td>আইছে।উঠতাম</td>\n      <td>ওইরে</td>\n      <td>হইতদি</td>\n      <td>প্লেয়ারগুলা</td>\n      <td>মার্কিউরি</td>\n      <td>ফইল্লেও</td>\n      <td>লইয়া</td>\n      <td>যেকুনু</td>\n      <td>যাইবো</td>\n      <td>হইছেগা</td>\n      <td>হইত্তর</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>নিবান্নাইস</td>\n      <td>আইট্টাই</td>\n      <td>ওঠলো</td>\n      <td>ইতে</td>\n      <td>দেইখাই</td>\n      <td>মার্কিউডির</td>\n      <td>লইয়া</td>\n      <td>হিরি-মিরি</td>\n      <td>কিচ্চু</td>\n      <td>গৈ</td>\n      <td>ফাচানব্বই</td>\n      <td>হাড়ে</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>নাগান</td>\n      <td>উডুক</td>\n      <td>সেহেন্তে</td>\n      <td>মাতিয়ারে</td>\n      <td>খেইলাই</td>\n      <td>থিকা</td>\n      <td>আইবোনে</td>\n      <td>ডাইন</td>\n      <td>বানাইয়া</td>\n      <td>কইছে</td>\n      <td>ওইয়া</td>\n      <td>কিয়ারে</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n\nProcessing train dataset...\nSaved: /kaggle/working/district_ood_dictionary_train.xlsx\nFirst few rows of train dataset:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     rangpur kishoreganj  narail chittagong narsingdi  tangail habiganj  \\\n0  কয়েকঝনের        রোডো    চইলে     অবস্তা    আমরাদি   এইন্যা    আইলাম   \n1     দিছলাম       বুজছো  তুমারে     ভাইয়া    মইধ্যে    খেইলা   মাতবার   \n2        ওটে        অইবো   মধ্যি       তুঁই   মোল্লাও    পাবজি     বন্দ   \n3       আচোং       দেলাও  কাইলকে    তোঁয়ার     লেখতে   দিছিলা     ছিনছ   \n4     ইয়্যা      চাইরশো  আসতিছি        খডে      ফারি  বুঝাইলা  মতুইরার   \n\n         barishal   sylhet     sandwip    comilla noakhali  \n0             শুব  খইনছাইন      আইচ্ছা  ভাল্লাগতো   ইয়ানে  \n1      ডিপারমেন্ট    আফনের      আমনেরা     যাইয়া  আড্ডাদি  \n2     সপটোওয়্যার   দিনখান  হিয়াল্লাই      আফনের  একজাগাত  \n3       ইনজিনারিং   দিনখাল      ইয়ানে      লইয়া    কোনাই  \n4  ইউনিবার্সিটিতে  কিলাখান        কউগা      গিয়া  সুজাহুর  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rangpur</th>\n      <th>kishoreganj</th>\n      <th>narail</th>\n      <th>chittagong</th>\n      <th>narsingdi</th>\n      <th>tangail</th>\n      <th>habiganj</th>\n      <th>barishal</th>\n      <th>sylhet</th>\n      <th>sandwip</th>\n      <th>comilla</th>\n      <th>noakhali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>কয়েকঝনের</td>\n      <td>রোডো</td>\n      <td>চইলে</td>\n      <td>অবস্তা</td>\n      <td>আমরাদি</td>\n      <td>এইন্যা</td>\n      <td>আইলাম</td>\n      <td>শুব</td>\n      <td>খইনছাইন</td>\n      <td>আইচ্ছা</td>\n      <td>ভাল্লাগতো</td>\n      <td>ইয়ানে</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>দিছলাম</td>\n      <td>বুজছো</td>\n      <td>তুমারে</td>\n      <td>ভাইয়া</td>\n      <td>মইধ্যে</td>\n      <td>খেইলা</td>\n      <td>মাতবার</td>\n      <td>ডিপারমেন্ট</td>\n      <td>আফনের</td>\n      <td>আমনেরা</td>\n      <td>যাইয়া</td>\n      <td>আড্ডাদি</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ওটে</td>\n      <td>অইবো</td>\n      <td>মধ্যি</td>\n      <td>তুঁই</td>\n      <td>মোল্লাও</td>\n      <td>পাবজি</td>\n      <td>বন্দ</td>\n      <td>সপটোওয়্যার</td>\n      <td>দিনখান</td>\n      <td>হিয়াল্লাই</td>\n      <td>আফনের</td>\n      <td>একজাগাত</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>আচোং</td>\n      <td>দেলাও</td>\n      <td>কাইলকে</td>\n      <td>তোঁয়ার</td>\n      <td>লেখতে</td>\n      <td>দিছিলা</td>\n      <td>ছিনছ</td>\n      <td>ইনজিনারিং</td>\n      <td>দিনখাল</td>\n      <td>ইয়ানে</td>\n      <td>লইয়া</td>\n      <td>কোনাই</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ইয়্যা</td>\n      <td>চাইরশো</td>\n      <td>আসতিছি</td>\n      <td>খডে</td>\n      <td>ফারি</td>\n      <td>বুঝাইলা</td>\n      <td>মতুইরার</td>\n      <td>ইউনিবার্সিটিতে</td>\n      <td>কিলাখান</td>\n      <td>কউগা</td>\n      <td>গিয়া</td>\n      <td>সুজাহুর</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n\nProcessing valid dataset...\nSaved: /kaggle/working/district_ood_dictionary_valid.xlsx\nFirst few rows of valid dataset:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   rangpur kishoreganj   narail chittagong narsingdi       tangail  habiganj  \\\n0    কওয়া       কয়ডা   সগোলতা        গরি       ইতা        পুইড়া  মুটামুটি   \n1    জানোং       লেখছছ     সবতা      আইডিত  মুজিকালে     মার্কেটেও       আঁস   \n2  সেইটায়        এইনো  ক্লহায়      অইলদি      তোকা    বঙ্গবাজারে     গিয়া   \n3   চইলবার       তিনডা     কইছে      এইগিন     ফারছও     ইসলামীয়া     তুমরা   \n4    লাগচে      চাইরটা   আনিছিস  লইয়্যেরে      ফারি  মার্কেটগুলার  বাজারোতে   \n\n  barishal  sylhet     sandwip          comilla  noakhali  \n0   আছিলাম   কিতাত         আঁই          দেশগুলা     আইবেন  \n1  ধরছিলাম    কিতা      হইল্লে  ব্যাবসা-বানিজ্য   কইলেয়ে  \n2    এট্টা   নিয়া  দিয়ালাইতো            নিয়া     তনিকা  \n3    ব্যার    ফড়ো       কিরবো          দেক-শোন  ধোয়েছের  \n4    কচুরী  মহিলাত  হাইত্তান্ন           সাপ্তা       আঁর  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rangpur</th>\n      <th>kishoreganj</th>\n      <th>narail</th>\n      <th>chittagong</th>\n      <th>narsingdi</th>\n      <th>tangail</th>\n      <th>habiganj</th>\n      <th>barishal</th>\n      <th>sylhet</th>\n      <th>sandwip</th>\n      <th>comilla</th>\n      <th>noakhali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>কওয়া</td>\n      <td>কয়ডা</td>\n      <td>সগোলতা</td>\n      <td>গরি</td>\n      <td>ইতা</td>\n      <td>পুইড়া</td>\n      <td>মুটামুটি</td>\n      <td>আছিলাম</td>\n      <td>কিতাত</td>\n      <td>আঁই</td>\n      <td>দেশগুলা</td>\n      <td>আইবেন</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>জানোং</td>\n      <td>লেখছছ</td>\n      <td>সবতা</td>\n      <td>আইডিত</td>\n      <td>মুজিকালে</td>\n      <td>মার্কেটেও</td>\n      <td>আঁস</td>\n      <td>ধরছিলাম</td>\n      <td>কিতা</td>\n      <td>হইল্লে</td>\n      <td>ব্যাবসা-বানিজ্য</td>\n      <td>কইলেয়ে</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>সেইটায়</td>\n      <td>এইনো</td>\n      <td>ক্লহায়</td>\n      <td>অইলদি</td>\n      <td>তোকা</td>\n      <td>বঙ্গবাজারে</td>\n      <td>গিয়া</td>\n      <td>এট্টা</td>\n      <td>নিয়া</td>\n      <td>দিয়ালাইতো</td>\n      <td>নিয়া</td>\n      <td>তনিকা</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>চইলবার</td>\n      <td>তিনডা</td>\n      <td>কইছে</td>\n      <td>এইগিন</td>\n      <td>ফারছও</td>\n      <td>ইসলামীয়া</td>\n      <td>তুমরা</td>\n      <td>ব্যার</td>\n      <td>ফড়ো</td>\n      <td>কিরবো</td>\n      <td>দেক-শোন</td>\n      <td>ধোয়েছের</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>লাগচে</td>\n      <td>চাইরটা</td>\n      <td>আনিছিস</td>\n      <td>লইয়্যেরে</td>\n      <td>ফারি</td>\n      <td>মার্কেটগুলার</td>\n      <td>বাজারোতে</td>\n      <td>কচুরী</td>\n      <td>মহিলাত</td>\n      <td>হাইত্তান্ন</td>\n      <td>সাপ্তা</td>\n      <td>আঁর</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n\nProcessing combined dataset...\nSaved: /kaggle/working/district_ood_dictionary_combined.xlsx\nFirst few rows of combined dataset:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    rangpur kishoreganj     narail chittagong  narsingdi     tangail  \\\n0    খাছিনো      রাখছোত  কিনা-কাটা       আইছস      কমানি        ইংলট   \n1      ইদোত      খানয়ও      খুড়ো  কিনিয়ারে    করতারমু  দ্যাড়-দুই   \n2  খাওয়াবে        আইছস    ফেলাইছো      লাইফত       আইছস  সমালোচনাডা   \n3    পঞ্চাস       অফিসো      ইমনরে     মুড়ির    গোস্তডা    ডেডিকেশন   \n4   আড়াইশো       ইয়তে     চালাতি       ফাকে  ডায়বিটিস   পীরগাছায়   \n\n   habiganj barishal      sylhet      sandwip     comilla    noakhali  \n0    দিতেনও   বেচছোস  রোহিঙ্গারে    ছড়া-টড়া  মরছিদেত্তে   হাচাইত্তর  \n1    ফাকেদা    কুডার     আটকাইতা        হোইলে    দানওয়কি      বিছনার  \n2     অফিসো   তোগোডা  বওয়াইছোইন        এমলাক       গুরুপ        কমতো  \n3  গুন-গাষি   হ্যারও      ওয়ানো   কুরবাইন্না      গেছিগা  মৃৎশিল্ফের  \n4    ওয়ানো   এয়াগো       অইরাম  বেরাই-গোরাই        গডনা         গোই  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rangpur</th>\n      <th>kishoreganj</th>\n      <th>narail</th>\n      <th>chittagong</th>\n      <th>narsingdi</th>\n      <th>tangail</th>\n      <th>habiganj</th>\n      <th>barishal</th>\n      <th>sylhet</th>\n      <th>sandwip</th>\n      <th>comilla</th>\n      <th>noakhali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>খাছিনো</td>\n      <td>রাখছোত</td>\n      <td>কিনা-কাটা</td>\n      <td>আইছস</td>\n      <td>কমানি</td>\n      <td>ইংলট</td>\n      <td>দিতেনও</td>\n      <td>বেচছোস</td>\n      <td>রোহিঙ্গারে</td>\n      <td>ছড়া-টড়া</td>\n      <td>মরছিদেত্তে</td>\n      <td>হাচাইত্তর</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ইদোত</td>\n      <td>খানয়ও</td>\n      <td>খুড়ো</td>\n      <td>কিনিয়ারে</td>\n      <td>করতারমু</td>\n      <td>দ্যাড়-দুই</td>\n      <td>ফাকেদা</td>\n      <td>কুডার</td>\n      <td>আটকাইতা</td>\n      <td>হোইলে</td>\n      <td>দানওয়কি</td>\n      <td>বিছনার</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>খাওয়াবে</td>\n      <td>আইছস</td>\n      <td>ফেলাইছো</td>\n      <td>লাইফত</td>\n      <td>আইছস</td>\n      <td>সমালোচনাডা</td>\n      <td>অফিসো</td>\n      <td>তোগোডা</td>\n      <td>বওয়াইছোইন</td>\n      <td>এমলাক</td>\n      <td>গুরুপ</td>\n      <td>কমতো</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>পঞ্চাস</td>\n      <td>অফিসো</td>\n      <td>ইমনরে</td>\n      <td>মুড়ির</td>\n      <td>গোস্তডা</td>\n      <td>ডেডিকেশন</td>\n      <td>গুন-গাষি</td>\n      <td>হ্যারও</td>\n      <td>ওয়ানো</td>\n      <td>কুরবাইন্না</td>\n      <td>গেছিগা</td>\n      <td>মৃৎশিল্ফের</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>আড়াইশো</td>\n      <td>ইয়তে</td>\n      <td>চালাতি</td>\n      <td>ফাকে</td>\n      <td>ডায়বিটিস</td>\n      <td>পীরগাছায়</td>\n      <td>ওয়ানো</td>\n      <td>এয়াগো</td>\n      <td>অইরাম</td>\n      <td>বেরাই-গোরাই</td>\n      <td>গডনা</td>\n      <td>গোই</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":23},{"id":"2263e5a3-edf2-474b-874c-ef60b6c55b25","cell_type":"code","source":"def get_phone_statistics(xlsx_path):\n    # Read the Excel file\n    df = pd.read_excel(xlsx_path)\n    \n    # 1. Calculate Characteristic Phones Pair Count\n    def count_phone_pairs(text):\n        # Convert Bengali text to a list of characters\n        text = str(text)\n        text = unicodedata.normalize('NFC', text)  # Normalize Unicode for Bengali\n        chars = list(text)\n        # Create pairs of consecutive characters\n        pairs = [''.join(pair) for pair in zip(chars[:-1], chars[1:])]\n        return len(set(pairs))\n    \n    phone_pair_count = df['transcripts'].dropna().apply(count_phone_pairs).mean()\n    \n    # 2. Calculate Average Phone Length Percentage\n    def calc_phone_length(text):\n        text = str(text)\n        text = unicodedata.normalize('NFC', text)  # Normalize Unicode for Bengali\n        phone_length = len(text.replace(' ', ''))  # Remove spaces\n        text_length = len(text.strip())  # Trim and count total length\n        return (phone_length / text_length) * 100 if text_length > 0 else 0\n    \n    avg_phone_length = df['transcripts'].dropna().apply(calc_phone_length).mean()\n    \n    # 3. Calculate Annotation Completeness\n    annot_completeness = (df['transcripts'].notna() & (df['transcripts'].str.strip().str.len() > 0)).mean() * 100\n    \n    return phone_pair_count, avg_phone_length, annot_completeness","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:38:22.580313Z","iopub.execute_input":"2025-01-31T13:38:22.580723Z","iopub.status.idle":"2025-01-31T13:38:22.589001Z","shell.execute_reply.started":"2025-01-31T13:38:22.580686Z","shell.execute_reply":"2025-01-31T13:38:22.587958Z"}},"outputs":[],"execution_count":7},{"id":"eda9391a-9a41-4f68-83e8-5d80d5c9a5a1","cell_type":"code","source":"import unicodedata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:37:01.802094Z","iopub.execute_input":"2025-01-30T19:37:01.802441Z","iopub.status.idle":"2025-01-30T19:37:01.806057Z","shell.execute_reply.started":"2025-01-30T19:37:01.802408Z","shell.execute_reply":"2025-01-30T19:37:01.805150Z"}},"outputs":[],"execution_count":20},{"id":"99ba506d","cell_type":"markdown","source":"# Experimenting","metadata":{"papermill":{"duration":0.017429,"end_time":"2024-08-22T14:06:03.280803","exception":false,"start_time":"2024-08-22T14:06:03.263374","status":"completed"},"tags":[]}},{"id":"f5efb177","cell_type":"code","source":"dis = 'Comilla'\npath = '/kaggle/input/interspeech-2025/district_wise/Comilla/Comilla_test.xlsx'\nbase_dir = '/kaggle/input/interspeech-2025/district_wise/Comilla/test'\n\noutput_1 = unique_words(path, dis)\n\ndataset = output_1[0]\ndataset_size = len(dataset)\nvocab_dict= output_1[1]\nall_words_list = output_1[2]\ntotal_number_of_words_in_the_dataset = output_1[3]\ntotal_number_of_unique_words_in_the_dataset = output_1[4]\nood_words_dataset = output_1[5]\ntotal_number_of_ood_words = output_1[6]\ntotal_number_of_unique_ood_words = output_1[7]\n\noov_perc_tot = total_number_of_ood_words/total_number_of_words_in_the_dataset\noov_perc_unq = total_number_of_unique_ood_words/total_number_of_unique_words_in_the_dataset\n\n\n\noutput_2 = duration(base_dir,dataset,total_number_of_words_in_the_dataset)\n\n\nprint(f\"###############################################{dis}###############################################\")\nprint()\nprint(f'Total Samples {dataset_size}')\nprint(f\"Total => {output_2[4]} \")\nprint(f\"Average record size => {output_2[2]} seconds\")\nprint(f\"Words per minute => {output_2[3]} \")\nprint(f'Words per sample: {output_2[5]} words')\nprint(f'Total number of unique words present in {dis} dataset: {total_number_of_unique_words_in_the_dataset}')\nprint(f'OOD% in {dis} dataset (Unique): {round(oov_perc_unq*100, 3)} %')\nprint(f'Total number of words present in {dis} dataset: {total_number_of_words_in_the_dataset}')\nprint(f'Total number of OOD words present in {dis} dataset: {total_number_of_ood_words}')\nprint(f'Total number of unique OOD words present in {dis} dataset: {total_number_of_unique_ood_words}')\n\nprint(f'OOD% in {dis} dataset (Total): {round(oov_perc_tot*100, 3)} %')\nprint()\nprint(f\"Total in seconds: {output_2[0]} seconds\")\nprint(f\"Total in Hours: {output_2[1]} hours\")\n\n\n","metadata":{"id":"2D2NozKhXN3g","outputId":"178aa7d5-d718-48e6-e0e4-889837e5ffa2","papermill":{"duration":0.709265,"end_time":"2024-08-22T14:06:04.007569","exception":true,"start_time":"2024-08-22T14:06:03.298304","status":"failed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:52:10.082368Z","iopub.execute_input":"2025-01-31T13:52:10.082658Z","iopub.status.idle":"2025-01-31T13:52:11.855111Z","shell.execute_reply.started":"2025-01-31T13:52:10.082636Z","shell.execute_reply":"2025-01-31T13:52:11.854328Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 32/32 [00:00<00:00, 38391.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"{'স্বর্ণকাররা': 1, 'স্বর্নকার': 1, 'হইছেগা': 1, 'ফাচানব্বই': 1, 'ওইয়া': 1, 'মাইনসের': 1, 'রূপাই': 1, 'বালো': 1, 'পিনতে': 1, 'পাচানব্বই': 1, 'টেয়ারও': 1, 'অহনে': 1, 'মেয়েরার': 1, 'বাড়ই': 1, 'ষাইড': 1, 'টেয়া': 1, 'নব্বইর': 1, 'অয়': 1, 'ছাইগা': 1, 'গেছেগা': 1, 'বাড়তেছে': 1, 'এইটুকই': 1, 'ওইদিনও': 1, 'মায়েরাই': 1, 'ছেলে-মেয়েদেরকে': 1, 'রুহিও': 1, 'ষোলোই': 1, 'রিয়ার্সেল': 1, 'ওইগুলার': 1, 'দশ-পনেরো': 1, 'আইয়ো': 1, 'মদ্যে': 1, 'দুলনা': 1, 'দোলনাতে': 1, 'যাইয়া': 1, 'লইছে': 1, 'ফ্রেন্ডটা': 1, 'মেয়েটার': 1, 'নুসাইবা': 1, 'নুসাইবার': 1, 'খেলা-ধুলা': 1, 'রিয়ার্সেলে': 1, 'ভাবলো': 1, 'ব্লুটুথে': 1, 'দোলনাটা': 1, 'ফিরা': 1, 'বান্ধুবি': 1, 'মদ্দে': 1, 'আছে।মানে': 1, 'চোখগুলা': 1, 'উল্টায়': 1, 'ছেলে-মেয়েরা': 1, 'করতাছেনা': 1, 'ভাবতেছে': 1, 'ছেলেগুলা': 1, 'দেখ-দেখ': 1, 'ভাবতাছে': 1, 'উইঠা': 1, 'রোদ্র': 1, 'দৌড়ায়া': 1, 'পারতেছে': 1, 'ফুইলা': 1, 'চিল্লান': 1, 'যেইভাবে': 1, 'ফরে': 1, 'নামাইছে': 1, 'নিয়া': 1, 'মেয়েরে': 1, 'এডা': 1, 'যাইতাছে': 1, 'মিল্লা': 1, 'ডে-শিফটের': 1, 'মরনিং': 1, 'শিফটের': 1, 'ওইছে': 1, 'ডে-শিফটে': 1, 'মূহুর্তেও': 1, 'কাড়া-কাড়ি': 1, 'উটবে': 1, 'শট্টা': 1, 'স্পর্শো': 1, 'রুহিরেও': 1, 'কারেন্টে': 1, 'বিষয়ডার': 1, 'ছিড়া': 1, 'এলমুনিয়ামের': 1, 'ইয়াগুলা': 1, 'রশিটাতেও': 1, 'বাচ্চারে': 1, 'শুক্রিয়া': 1, 'বাবা-মা-এর': 1, 'ইনজিনিয়ার': 1, 'ইয়াতে': 1, 'যহন': 1, 'পাইয়া': 1, 'বেথা': 1, 'বল্লো': 1, 'রুহিরে': 1, 'যাইতে-যাইতেই': 1, 'আরকিহ': 1, 'ঘটনাডা': 1, 'রুহিরও': 1, 'চইলা': 1, 'সাপ্তাহ': 1, 'ট্রমার': 1, 'পাইতো': 1, 'বান্দবির': 1, 'ওয়': 1, 'ঝুলায়': 1, 'বারডেতে': 1, 'বলমু': 1, 'আন্ডারেই': 1, 'ওরকমভাবে': 1, 'মেডামের': 1, 'বইলাই': 1, 'তাকটা': 1, 'ছিড়ে': 1, 'ছিড়ছে': 1, 'যাইতো': 1, 'দোলনাটার': 1, 'গার্ডগুলা': 1, 'বডার': 1, 'দীর্গ': 1, 'বসর': 1, 'সোদিতে': 1, 'আমাত্তে': 1, 'পতিবশশরে-বশশরে': 1, 'তাইকা': 1, 'এই-সেই': 1}\n['স্বর্ণকাররা', 'স্বর্নকার', 'হইছেগা', 'ফাচানব্বই', 'ওইয়া', 'মাইনসের', 'রূপাই', 'বালো', 'পিনতে', 'পাচানব্বই', 'টেয়ারও', 'অহনে', 'মেয়েরার', 'বাড়ই', 'ষাইড', 'টেয়া', 'নব্বইর', 'অয়', 'ছাইগা', 'গেছেগা', 'বাড়তেছে', 'এইটুকই', 'ওইদিনও', 'মায়েরাই', 'ছেলে-মেয়েদেরকে', 'রুহিও', 'ষোলোই', 'রিয়ার্সেল', 'ওইগুলার', 'দশ-পনেরো', 'আইয়ো', 'মদ্যে', 'দুলনা', 'দোলনাতে', 'যাইয়া', 'লইছে', 'ফ্রেন্ডটা', 'মেয়েটার', 'নুসাইবা', 'নুসাইবার', 'খেলা-ধুলা', 'রিয়ার্সেলে', 'ভাবলো', 'ব্লুটুথে', 'দোলনাটা', 'ফিরা', 'বান্ধুবি', 'মদ্দে', 'আছে।মানে', 'চোখগুলা', 'উল্টায়', 'ছেলে-মেয়েরা', 'করতাছেনা', 'ভাবতেছে', 'ছেলেগুলা', 'দেখ-দেখ', 'ভাবতাছে', 'উইঠা', 'রোদ্র', 'দৌড়ায়া', 'পারতেছে', 'ফুইলা', 'চিল্লান', 'যেইভাবে', 'ফরে', 'নামাইছে', 'নিয়া', 'মেয়েরে', 'এডা', 'যাইতাছে', 'মিল্লা', 'ডে-শিফটের', 'মরনিং', 'শিফটের', 'ওইছে', 'ডে-শিফটে', 'মূহুর্তেও', 'কাড়া-কাড়ি', 'উটবে', 'শট্টা', 'স্পর্শো', 'রুহিরেও', 'কারেন্টে', 'বিষয়ডার', 'ছিড়া', 'এলমুনিয়ামের', 'ইয়াগুলা', 'রশিটাতেও', 'বাচ্চারে', 'শুক্রিয়া', 'বাবা-মা-এর', 'ইনজিনিয়ার', 'ইয়াতে', 'যহন', 'পাইয়া', 'বেথা', 'বল্লো', 'রুহিরে', 'যাইতে-যাইতেই', 'আরকিহ', 'ঘটনাডা', 'রুহিরও', 'চইলা', 'সাপ্তাহ', 'ট্রমার', 'পাইতো', 'বান্দবির', 'ওয়', 'ঝুলায়', 'বারডেতে', 'বলমু', 'আন্ডারেই', 'ওরকমভাবে', 'মেডামের', 'বইলাই', 'তাকটা', 'ছিড়ে', 'ছিড়ছে', 'যাইতো', 'দোলনাটার', 'গার্ডগুলা', 'বডার', 'দীর্গ', 'বসর', 'সোদিতে', 'আমাত্তে', 'পতিবশশরে-বশশরে', 'তাইকা', 'এই-সেই']\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 32/32 [00:00<00:00, 47.90it/s]","output_type":"stream"},{"name":"stdout","text":"###############################################Comilla###############################################\n\nTotal Samples 32\nTotal => 0:08:51 \nAverage record size => 16.582 seconds\nWords per minute => 178.375 \nWords per sample: 44.594 words\nTotal number of unique words present in Comilla dataset: 589\nOOD% in Comilla dataset (Unique): 21.902 %\nTotal number of words present in Comilla dataset: 1427\nTotal number of OOD words present in Comilla dataset: 129\nTotal number of unique OOD words present in Comilla dataset: 129\nOOD% in Comilla dataset (Total): 9.04 %\n\nTotal in seconds: 530.612 seconds\nTotal in Hours: 0.147 hours\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"id":"9eec680b","cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"a4042b7f","cell_type":"markdown","source":"# Main datasets","metadata":{"id":"rzKn2aE4oE4A","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"2c5ab16a","cell_type":"code","source":"rangpur_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/rangpur.xlsx\")\nkishoreganj_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/kishoreganj.xlsx\")\nnarail_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/narail.xlsx\")\nchittagong_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/chittagong.xlsx\")\nnarsingdi_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/narsingdi.xlsx\")\ntangail_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/tangail.xlsx\")\nhabiganj_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/habiganj.xlsx\")\nbarishal_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/barishal.xlsx\")\nsylhet_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/sylhet.xlsx\")\nsandwip_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/sandwip.xlsx\")\n\n\n\ndists = [\"rangpur\", \"kishoreganj\", \"narail\", \"chittagong\", \"narsingdi\", \"tangail\", \"habiganj\", \"barishal\", \"sylhet\", \"sandwip\"]\n\ndis_words = {}\n\nfor dis in dists:\n    \n    if dis == \"all\":\n        thesis_df = pd.concat([rangpur_df,kishoreganj_df,narail_df,chittagong_df,narsingdi_df], axis = 0)\n        path = thesis_df\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/all'\n        \n    else:\n\n        path = f'/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/{dis}.xlsx'\n        base_dir = f'/kaggle/input/only-dis/only_dis/only_dis/{dis}/'\n\n    dis = dis.capitalize()\n\n    output_1 = unique_words(path, dis)\n    \n    dataset = output_1[0]\n    dataset_size = len(dataset)\n    vocab_dict= output_1[1]\n    all_words_list = output_1[2]\n    total_number_of_words_in_the_dataset = output_1[3]\n    total_number_of_unique_words_in_the_dataset = output_1[4]\n    ood_words_dataset = output_1[5]\n    total_number_of_ood_words = output_1[6]\n    total_number_of_unique_ood_words = output_1[7]\n    dis_words[dis] = output_1[8]\n    \n\n    oov_perc_unq = total_number_of_unique_ood_words/total_number_of_unique_words_in_the_dataset\n    oov_perc_tot = total_number_of_ood_words/total_number_of_words_in_the_dataset\n \n    output_2 = duration(base_dir,dataset,total_number_of_words_in_the_dataset)\n\n\n    print(f\"====================================================== {dis} ======================================================\")\n    print()\n    print()\n    print()\n    print(f'Total Samples {dataset_size}')\n    print(f'Total number of words present in {dis} dataset: {total_number_of_words_in_the_dataset}')\n    print(f'Total number of unique words present in {dis} dataset: {total_number_of_unique_words_in_the_dataset}')\n    print(f'Total number of OOD words present in {dis} dataset: {total_number_of_ood_words}')\n    print(f'Total number of unique OOD words present in {dis} dataset: {total_number_of_unique_ood_words}')\n    print(f'OOD% in {dis} dataset (Unique words): {round(oov_perc_unq*100, 3)} %')\n    print(f'OOD% in {dis} dataset (Total words): {round(oov_perc_tot*100, 3)} %')\n    print()\n    print(f\"Total Duration: {output_2[4]}\")\n    print(f\"Total in seconds: {output_2[0]} seconds\")\n    print(f\"Total in Hours: {output_2[1]} hours\")\n    print(f\"Average record size: {output_2[2]} seconds\")\n    print(f\"Words per minute: {output_2[3]} \")\n    print(f'Words per sample: {output_2[5]} words')\n    print()\n    print()\n    print()\n    print(f\"###################################################################################################################\")\n    print()\n    print()\n    print()\n    \n\noutput_df = pd.DataFrame()\n\nfor dis in dists:\n    output_df = pd.concat(\n        [output_df,\n         pd.DataFrame({dis : dis_words[dis]})],\n        axis=1\n    )\noutput_df.to_excel(\"district_ood.xlsx\", index=False)","metadata":{"execution":{"iopub.execute_input":"2024-08-22T12:48:06.790279Z","iopub.status.busy":"2024-08-22T12:48:06.789842Z","iopub.status.idle":"2024-08-22T12:48:14.077540Z","shell.execute_reply":"2024-08-22T12:48:14.076135Z","shell.execute_reply.started":"2024-08-22T12:48:06.790242Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"72f32052","cell_type":"markdown","source":"# Subsets","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"5d9c7a67","cell_type":"code","source":"import pandas as pd\n\nrangpur_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/rangpur.xlsx\")\nkishoreganj_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/kishoreganj.xlsx\")\nnarail_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/narail.xlsx\")\nchittagong_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/chittagong.xlsx\")\nnarsingdi_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/narsingdi.xlsx\")\ntangail_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/tangail.xlsx\")\nhabiganj_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/habiganj.xlsx\")\nbarishal_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/barishal.xlsx\")\nsylhet_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/sylhet.xlsx\")\nsandwip_df = pd.read_excel(\"/kaggle/input/only-dis/dis_only_dataframes/dis_only_dataframes/sandwip.xlsx\")\n\n\nrangpur_train = rangpur_df[rangpur_df[\"Split\"] == \"Train\"]\nrangpur_test = rangpur_df[rangpur_df[\"Split\"] == \"Test\"]\nrangpur_valid = rangpur_df[rangpur_df[\"Split\"] == \"Valid\"]\n\nkishoreganj_train = kishoreganj_df[kishoreganj_df[\"Split\"] == \"Train\"]\nkishoreganj_test = kishoreganj_df[kishoreganj_df[\"Split\"] == \"Test\"]\nkishoreganj_valid = kishoreganj_df[kishoreganj_df[\"Split\"] == \"Valid\"]\n\nnarail_train = narail_df[narail_df[\"Split\"] == \"Train\"]\nnarail_test = narail_df[narail_df[\"Split\"] == \"Test\"]\nnarail_valid = narail_df[narail_df[\"Split\"] == \"Valid\"]\n\nchittagong_train = chittagong_df[chittagong_df[\"Split\"] == \"Train\"]\nchittagong_test = chittagong_df[chittagong_df[\"Split\"] == \"Test\"]\nchittagong_valid = chittagong_df[chittagong_df[\"Split\"] == \"Valid\"]\n\nnarsingdi_train = narsingdi_df[narsingdi_df[\"Split\"] == \"Train\"]\nnarsingdi_test = narsingdi_df[narsingdi_df[\"Split\"] == \"Test\"]\nnarsingdi_valid = narsingdi_df[narsingdi_df[\"Split\"] == \"Valid\"]\n\ntangail_train = tangail_df[tangail_df[\"Split\"] == \"Train\"]\ntangail_test = tangail_df[tangail_df[\"Split\"] == \"Test\"]\ntangail_valid = tangail_df[tangail_df[\"Split\"] == \"Valid\"]\n\nhabiganj_train = habiganj_df[habiganj_df[\"Split\"] == \"Train\"]\nhabiganj_test = habiganj_df[habiganj_df[\"Split\"] == \"Test\"]\nhabiganj_valid = habiganj_df[habiganj_df[\"Split\"] == \"Valid\"]\n\nbarishal_train = barishal_df[barishal_df[\"Split\"] == \"Train\"]\nbarishal_test = barishal_df[barishal_df[\"Split\"] == \"Test\"]\nbarishal_valid = barishal_df[barishal_df[\"Split\"] == \"Valid\"]\n\nsylhet_train = sylhet_df[sylhet_df[\"Split\"] == \"Train\"]\nsylhet_test = sylhet_df[sylhet_df[\"Split\"] == \"Test\"]\nsylhet_valid = sylhet_df[sylhet_df[\"Split\"] == \"Valid\"]\n\nsandwip_train = sandwip_df[sandwip_df[\"Split\"] == \"Train\"]\nsandwip_test = sandwip_df[sandwip_df[\"Split\"] == \"Test\"]\nsandwip_valid = sandwip_df[sandwip_df[\"Split\"] == \"Valid\"]\n\n\n########################################################################\n\nall_df = pd.concat([rangpur_df,kishoreganj_df,narail_df,chittagong_df,narsingdi_df,\n                    tangail_df,habiganj_df,barishal_df,sylhet_df,sandwip_df], axis = 0)\n\nall_train = all_df[all_df[\"Split\"] == \"Train\"]\nall_test = all_df[all_df[\"Split\"] == \"Test\"]\nall_valid = all_df[all_df[\"Split\"] == \"Valid\"]","metadata":{"execution":{"iopub.execute_input":"2024-08-11T12:52:45.692540Z","iopub.status.busy":"2024-08-11T12:52:45.692164Z","iopub.status.idle":"2024-08-11T12:52:50.793195Z","shell.execute_reply":"2024-08-11T12:52:50.791874Z","shell.execute_reply.started":"2024-08-11T12:52:45.692510Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"579924b8","cell_type":"code","source":"all_df_thesis = pd.concat([rangpur_df,kishoreganj_df,narail_df,chittagong_df,narsingdi_df], axis = 0)\n\n\nall_train_thesis = all_df_thesis[all_df_thesis[\"Split\"] == \"Train\"]\nall_test_thesis = all_df_thesis[all_df_thesis[\"Split\"] == \"Test\"]\nall_valid_thesis = all_df_thesis[all_df_thesis[\"Split\"] == \"Valid\"]","metadata":{"execution":{"iopub.execute_input":"2024-08-11T12:52:50.797513Z","iopub.status.busy":"2024-08-11T12:52:50.797145Z","iopub.status.idle":"2024-08-11T12:52:50.815508Z","shell.execute_reply":"2024-08-11T12:52:50.814338Z","shell.execute_reply.started":"2024-08-11T12:52:50.797483Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"cf7cf4f9","cell_type":"markdown","source":"# Train","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"f6e7a05b","cell_type":"code","source":"trains = [rangpur_train, kishoreganj_train, narail_train, chittagong_train, narsingdi_train, all_train]\ndists = [\"rangpur\", \"kishoreganj\", \"narail\", \"chittagong\", \"narsingdi\", \"all\"]\n\n\nfor dis in dists:\n    \n    if dis == 'rangpur':\n        df = rangpur_train\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'kishoreganj':\n        df = kishoreganj_train\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'narail':\n        df = narail_train\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'chittagong':\n        df = chittagong_train\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'narsingdi':\n        df = narsingdi_train\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'all':\n        df = all_train_thesis\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/splits/train/'\n    \n\n    dis = dis.capitalize()\n\n    output_1 = unique_words(df, dis)\n    \n    dataset = output_1[0]\n    dataset_size = len(dataset)\n    vocab_dict= output_1[1]\n    all_words_list = output_1[2]\n    total_number_of_words_in_the_dataset = output_1[3]\n    total_number_of_unique_words_in_the_dataset = output_1[4]\n    ood_words_dataset = output_1[5]\n    total_number_of_ood_words = output_1[6]\n    total_number_of_unique_ood_words = output_1[7]\n\n    oov_perc_unq = total_number_of_unique_ood_words/total_number_of_unique_words_in_the_dataset\n    oov_perc_tot = total_number_of_ood_words/total_number_of_words_in_the_dataset\n \n    output_2 = duration(base_dir,dataset,total_number_of_words_in_the_dataset)\n\n\n    print(f\"====================================================== {dis} ======================================================\")\n    print()\n    print(f'Total Samples {dataset_size}')\n    print(f'Total number of words present in {dis} dataset: {total_number_of_words_in_the_dataset}')\n    print(f'Total number of unique words present in {dis} dataset: {total_number_of_unique_words_in_the_dataset}')\n    print(f'Total number of OOD words present in {dis} dataset: {total_number_of_ood_words}')\n    print(f'Total number of unique OOD words present in {dis} dataset: {total_number_of_unique_ood_words}')\n    print(f'OOD% in {dis} dataset (Unique words): {round(oov_perc_unq*100, 3)} %')\n    print(f'OOD% in {dis} dataset (Total words): {round(oov_perc_tot*100, 3)} %')\n    print()\n    print(f\"Total Duration: {output_2[4]}\")\n    print(f\"Total in seconds: {output_2[0]} seconds\")\n    print(f\"Total in Hours: {output_2[1]} hours\")\n    print(f\"Average record size: {output_2[2]} seconds\")\n    print(f\"Words per minute: {output_2[3]} \")\n    print(f'Words per sample: {output_2[5]} words')\n    print()\n    print()\n    print()\n    print(f\"###################################################################################################################\")\n    print()\n    print()\n","metadata":{"execution":{"iopub.execute_input":"2024-08-11T12:52:50.817544Z","iopub.status.busy":"2024-08-11T12:52:50.817145Z","iopub.status.idle":"2024-08-11T13:17:30.295241Z","shell.execute_reply":"2024-08-11T13:17:30.293798Z","shell.execute_reply.started":"2024-08-11T12:52:50.817512Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"b92a3686","cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"b7978461","cell_type":"markdown","source":"# Test","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"caea5c16","cell_type":"code","source":"trains = [rangpur_test, kishoreganj_test, narail_test, chittagong_test, narsingdi_test, all_test]\ndists = [\"rangpur\", \"kishoreganj\", \"narail\", \"chittagong\", \"narsingdi\", \"all\"]\n\nfor dis in dists:\n    \n    if dis == 'rangpur':\n        df = rangpur_test\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'kishoreganj':\n        df = kishoreganj_test\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'narail':\n        df = narail_test\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'chittagong':\n        df = chittagong_test\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'narsingdi':\n        df = narsingdi_test\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'all':\n        df = all_test_thesis\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/splits/test/'\n    \n\n    dis = dis.capitalize()\n\n    output_1 = unique_words(df, dis)\n    \n    dataset = output_1[0]\n    dataset_size = len(dataset)\n    vocab_dict= output_1[1]\n    all_words_list = output_1[2]\n    total_number_of_words_in_the_dataset = output_1[3]\n    total_number_of_unique_words_in_the_dataset = output_1[4]\n    ood_words_dataset = output_1[5]\n    total_number_of_ood_words = output_1[6]\n    total_number_of_unique_ood_words = output_1[7]\n\n    oov_perc_unq = total_number_of_unique_ood_words/total_number_of_unique_words_in_the_dataset\n    oov_perc_tot = total_number_of_ood_words/total_number_of_words_in_the_dataset\n \n    output_2 = duration(base_dir,dataset,total_number_of_words_in_the_dataset)\n\n\n    print(f\"====================================================== {dis} ======================================================\")\n    print()\n    print(f'Total Samples {dataset_size}')\n    print(f'Total number of words present in {dis} dataset: {total_number_of_words_in_the_dataset}')\n    print(f'Total number of unique words present in {dis} dataset: {total_number_of_unique_words_in_the_dataset}')\n    print(f'Total number of OOD words present in {dis} dataset: {total_number_of_ood_words}')\n    print(f'Total number of unique OOD words present in {dis} dataset: {total_number_of_unique_ood_words}')\n    print(f'OOD% in {dis} dataset (Unique words): {round(oov_perc_unq*100, 3)} %')\n    print(f'OOD% in {dis} dataset (Total words): {round(oov_perc_tot*100, 3)} %')\n    print()\n    print(f\"Total Duration: {output_2[4]}\")\n    print(f\"Total in seconds: {output_2[0]} seconds\")\n    print(f\"Total in Hours: {output_2[1]} hours\")\n    print(f\"Average record size: {output_2[2]} seconds\")\n    print(f\"Words per minute: {output_2[3]} \")\n    print(f'Words per sample: {output_2[5]} words')\n    print()\n    print()\n    print()\n    print(f\"###################################################################################################################\")\n    print()\n    print()\n","metadata":{"execution":{"iopub.execute_input":"2024-08-11T13:17:30.297282Z","iopub.status.busy":"2024-08-11T13:17:30.296752Z","iopub.status.idle":"2024-08-11T13:21:13.087535Z","shell.execute_reply":"2024-08-11T13:21:13.086301Z","shell.execute_reply.started":"2024-08-11T13:17:30.297223Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"3c5268b2","cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"018c8f7c","cell_type":"markdown","source":"# Valid","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"932ea61f","cell_type":"code","source":"trains = [rangpur_valid, kishoreganj_valid, narail_valid, chittagong_valid, narsingdi_valid, all_valid]\ndists = [\"rangpur\", \"kishoreganj\", \"narail\", \"chittagong\", \"narsingdi\", \"all\"]\n\nfor dis in dists:\n    \n    if dis == 'rangpur':\n        df = rangpur_valid\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'kishoreganj':\n        df = kishoreganj_valid\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'narail':\n        df = narail_valid\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'chittagong':\n        df = chittagong_valid\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'narsingdi':\n        df = narsingdi_valid\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/{dis}/'\n    elif dis == 'all':\n        df = all_valid_thesis\n        base_dir = f'/kaggle/input/thesis-copy/thesis copy/audios/splits/valid/'\n    \n\n    dis = dis.capitalize()\n\n    output_1 = unique_words(df, dis)\n    \n    dataset = output_1[0]\n    dataset_size = len(dataset)\n    vocab_dict= output_1[1]\n    all_words_list = output_1[2]\n    total_number_of_words_in_the_dataset = output_1[3]\n    total_number_of_unique_words_in_the_dataset = output_1[4]\n    ood_words_dataset = output_1[5]\n    total_number_of_ood_words = output_1[6]\n    total_number_of_unique_ood_words = output_1[7]\n\n    oov_perc_unq = total_number_of_unique_ood_words/total_number_of_unique_words_in_the_dataset\n    oov_perc_tot = total_number_of_ood_words/total_number_of_words_in_the_dataset\n \n    output_2 = duration(base_dir,dataset,total_number_of_words_in_the_dataset)\n\n\n    print(f\"====================================================== {dis} ======================================================\")\n    print()\n    print(f'Total Samples {dataset_size}')\n    print(f'Total number of words present in {dis} dataset: {total_number_of_words_in_the_dataset}')\n    print(f'Total number of unique words present in {dis} dataset: {total_number_of_unique_words_in_the_dataset}')\n    print(f'Total number of OOD words present in {dis} dataset: {total_number_of_ood_words}')\n    print(f'Total number of unique OOD words present in {dis} dataset: {total_number_of_unique_ood_words}')\n    print(f'OOD% in {dis} dataset (Unique words): {round(oov_perc_unq*100, 3)} %')\n    print(f'OOD% in {dis} dataset (Total words): {round(oov_perc_tot*100, 3)} %')\n    print()\n    print(f\"Total Duration: {output_2[4]}\")\n    print(f\"Total in seconds: {output_2[0]} seconds\")\n    print(f\"Total in Hours: {output_2[1]} hours\")\n    print(f\"Average record size: {output_2[2]} seconds\")\n    print(f\"Words per minute: {output_2[3]} \")\n    print(f'Words per sample: {output_2[5]} words')\n    print()\n    print()\n    print()\n    print(f\"###################################################################################################################\")\n    print()\n    print()\n","metadata":{"execution":{"iopub.execute_input":"2024-08-11T13:21:13.089816Z","iopub.status.busy":"2024-08-11T13:21:13.089415Z","iopub.status.idle":"2024-08-11T13:24:41.061669Z","shell.execute_reply":"2024-08-11T13:24:41.060578Z","shell.execute_reply.started":"2024-08-11T13:21:13.089768Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"ec27ca54","cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null}]}